{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9YG0AdaxYdpu"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZVthUBNAYi6J"
   },
   "outputs": [],
   "source": [
    "#Model Creation\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "I76i_ZX9YlQt",
    "outputId": "81d441f8-ba0a-4fc1-f64d-ffe957c464c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_data=ImageDataGenerator(\n",
    "        rotation_range=20,     #randomly rotate images in the range (20 degrees)\n",
    "        horizontal_flip=True,  #randomly flip images\n",
    "        width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
    "        shear_range = 0.2,     #Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "        height_shift_range=0.1,#randomly shift images vertically (fraction of total height)\n",
    "        zoom_range=0.2,        #Range for random zoom\n",
    "        brightness_range = (0.5, 1.5))   #Range for picking a brightness shift value\n",
    "aug_data.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "iKhzPn7_Yor9",
    "outputId": "bb0a3f0e-b5fb-43fe-9e48-6f7d6ac815e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.0889 - accuracy: 0.0757\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.15870, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 4.0889 - accuracy: 0.0757 - val_loss: 3.5914 - val_accuracy: 0.1587\n",
      "Epoch 2/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.5026 - accuracy: 0.1671\n",
      "Epoch 00002: val_accuracy improved from 0.15870 to 0.21350, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 3.5026 - accuracy: 0.1671 - val_loss: 3.2227 - val_accuracy: 0.2135\n",
      "Epoch 3/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.2327 - accuracy: 0.2170\n",
      "Epoch 00003: val_accuracy improved from 0.21350 to 0.24960, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 3.2327 - accuracy: 0.2170 - val_loss: 3.0945 - val_accuracy: 0.2496\n",
      "Epoch 4/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.0631 - accuracy: 0.2469\n",
      "Epoch 00004: val_accuracy improved from 0.24960 to 0.28720, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 3.0631 - accuracy: 0.2469 - val_loss: 2.8502 - val_accuracy: 0.2872\n",
      "Epoch 5/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.9299 - accuracy: 0.2747\n",
      "Epoch 00005: val_accuracy improved from 0.28720 to 0.30440, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.9299 - accuracy: 0.2747 - val_loss: 2.8316 - val_accuracy: 0.3044\n",
      "Epoch 6/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.8171 - accuracy: 0.2962\n",
      "Epoch 00006: val_accuracy improved from 0.30440 to 0.33640, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.8171 - accuracy: 0.2962 - val_loss: 2.6255 - val_accuracy: 0.3364\n",
      "Epoch 7/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.7178 - accuracy: 0.3167\n",
      "Epoch 00007: val_accuracy improved from 0.33640 to 0.34500, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 2.7178 - accuracy: 0.3167 - val_loss: 2.6142 - val_accuracy: 0.3450\n",
      "Epoch 8/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.6384 - accuracy: 0.3303\n",
      "Epoch 00008: val_accuracy improved from 0.34500 to 0.36570, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.6384 - accuracy: 0.3303 - val_loss: 2.5199 - val_accuracy: 0.3657\n",
      "Epoch 9/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.5676 - accuracy: 0.3477\n",
      "Epoch 00009: val_accuracy improved from 0.36570 to 0.38300, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.5676 - accuracy: 0.3477 - val_loss: 2.4217 - val_accuracy: 0.3830\n",
      "Epoch 10/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.5042 - accuracy: 0.3602\n",
      "Epoch 00010: val_accuracy did not improve from 0.38300\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.5042 - accuracy: 0.3602 - val_loss: 2.4315 - val_accuracy: 0.3828\n",
      "Epoch 11/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.4589 - accuracy: 0.3700\n",
      "Epoch 00011: val_accuracy did not improve from 0.38300\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.4589 - accuracy: 0.3700 - val_loss: 2.4598 - val_accuracy: 0.3763\n",
      "Epoch 12/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.3998 - accuracy: 0.3820\n",
      "Epoch 00012: val_accuracy improved from 0.38300 to 0.39720, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 2.3998 - accuracy: 0.3820 - val_loss: 2.3571 - val_accuracy: 0.3972\n",
      "Epoch 13/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.3567 - accuracy: 0.3905\n",
      "Epoch 00013: val_accuracy did not improve from 0.39720\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.3567 - accuracy: 0.3905 - val_loss: 2.4132 - val_accuracy: 0.3904\n",
      "Epoch 14/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.3079 - accuracy: 0.4031\n",
      "Epoch 00014: val_accuracy did not improve from 0.39720\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.3079 - accuracy: 0.4031 - val_loss: 2.3502 - val_accuracy: 0.3960\n",
      "Epoch 15/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.2674 - accuracy: 0.4081\n",
      "Epoch 00015: val_accuracy improved from 0.39720 to 0.40630, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.2674 - accuracy: 0.4081 - val_loss: 2.3415 - val_accuracy: 0.4063\n",
      "Epoch 16/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.2379 - accuracy: 0.4163\n",
      "Epoch 00016: val_accuracy improved from 0.40630 to 0.41510, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 132ms/step - loss: 2.2379 - accuracy: 0.4163 - val_loss: 2.2776 - val_accuracy: 0.4151\n",
      "Epoch 17/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.2111 - accuracy: 0.4213\n",
      "Epoch 00017: val_accuracy improved from 0.41510 to 0.43450, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.2111 - accuracy: 0.4213 - val_loss: 2.2188 - val_accuracy: 0.4345\n",
      "Epoch 18/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1681 - accuracy: 0.4321\n",
      "Epoch 00018: val_accuracy did not improve from 0.43450\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.1681 - accuracy: 0.4321 - val_loss: 2.1926 - val_accuracy: 0.4338\n",
      "Epoch 19/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1540 - accuracy: 0.4328\n",
      "Epoch 00019: val_accuracy did not improve from 0.43450\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 2.1540 - accuracy: 0.4328 - val_loss: 2.2473 - val_accuracy: 0.4235\n",
      "Epoch 20/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1201 - accuracy: 0.4423\n",
      "Epoch 00020: val_accuracy did not improve from 0.43450\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 2.1201 - accuracy: 0.4423 - val_loss: 2.2391 - val_accuracy: 0.4336\n",
      "Epoch 21/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0887 - accuracy: 0.4446\n",
      "Epoch 00021: val_accuracy improved from 0.43450 to 0.44940, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.0887 - accuracy: 0.4446 - val_loss: 2.1290 - val_accuracy: 0.4494\n",
      "Epoch 22/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0653 - accuracy: 0.4505\n",
      "Epoch 00022: val_accuracy did not improve from 0.44940\n",
      "391/391 [==============================] - 51s 132ms/step - loss: 2.0653 - accuracy: 0.4505 - val_loss: 2.1605 - val_accuracy: 0.4427\n",
      "Epoch 23/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0418 - accuracy: 0.4555\n",
      "Epoch 00023: val_accuracy did not improve from 0.44940\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.0418 - accuracy: 0.4555 - val_loss: 2.1642 - val_accuracy: 0.4417\n",
      "Epoch 24/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0320 - accuracy: 0.4600\n",
      "Epoch 00024: val_accuracy improved from 0.44940 to 0.45490, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 132ms/step - loss: 2.0320 - accuracy: 0.4600 - val_loss: 2.0899 - val_accuracy: 0.4549\n",
      "Epoch 25/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0058 - accuracy: 0.4684\n",
      "Epoch 00025: val_accuracy did not improve from 0.45490\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 2.0058 - accuracy: 0.4684 - val_loss: 2.2621 - val_accuracy: 0.4246\n",
      "Epoch 26/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9938 - accuracy: 0.4684\n",
      "Epoch 00026: val_accuracy improved from 0.45490 to 0.45780, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.9938 - accuracy: 0.4684 - val_loss: 2.1161 - val_accuracy: 0.4578\n",
      "Epoch 27/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9742 - accuracy: 0.4747\n",
      "Epoch 00027: val_accuracy did not improve from 0.45780\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 1.9742 - accuracy: 0.4747 - val_loss: 2.1161 - val_accuracy: 0.4567\n",
      "Epoch 28/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9311 - accuracy: 0.4824\n",
      "Epoch 00028: val_accuracy did not improve from 0.45780\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.9311 - accuracy: 0.4824 - val_loss: 2.1726 - val_accuracy: 0.4512\n",
      "Epoch 29/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9366 - accuracy: 0.4795\n",
      "Epoch 00029: val_accuracy did not improve from 0.45780\n",
      "391/391 [==============================] - 52s 134ms/step - loss: 1.9366 - accuracy: 0.4795 - val_loss: 2.1709 - val_accuracy: 0.4534\n",
      "Epoch 30/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9178 - accuracy: 0.4831\n",
      "Epoch 00030: val_accuracy improved from 0.45780 to 0.46240, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 1.9178 - accuracy: 0.4831 - val_loss: 2.1109 - val_accuracy: 0.4624\n",
      "Epoch 31/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8915 - accuracy: 0.4895\n",
      "Epoch 00031: val_accuracy did not improve from 0.46240\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 1.8915 - accuracy: 0.4895 - val_loss: 2.0643 - val_accuracy: 0.4624\n",
      "Epoch 32/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8891 - accuracy: 0.4917\n",
      "Epoch 00032: val_accuracy did not improve from 0.46240\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.8891 - accuracy: 0.4917 - val_loss: 2.2026 - val_accuracy: 0.4457\n",
      "Epoch 33/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8682 - accuracy: 0.4951\n",
      "Epoch 00033: val_accuracy improved from 0.46240 to 0.46420, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.8682 - accuracy: 0.4951 - val_loss: 2.1030 - val_accuracy: 0.4642\n",
      "Epoch 34/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8559 - accuracy: 0.4965\n",
      "Epoch 00034: val_accuracy did not improve from 0.46420\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.8559 - accuracy: 0.4965 - val_loss: 2.1584 - val_accuracy: 0.4599\n",
      "Epoch 35/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8366 - accuracy: 0.5042\n",
      "Epoch 00035: val_accuracy improved from 0.46420 to 0.47090, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.8366 - accuracy: 0.5042 - val_loss: 2.0529 - val_accuracy: 0.4709\n",
      "Epoch 36/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8199 - accuracy: 0.5048\n",
      "Epoch 00036: val_accuracy did not improve from 0.47090\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.8199 - accuracy: 0.5048 - val_loss: 2.2045 - val_accuracy: 0.4510\n",
      "Epoch 37/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8100 - accuracy: 0.5071\n",
      "Epoch 00037: val_accuracy improved from 0.47090 to 0.47660, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.8100 - accuracy: 0.5071 - val_loss: 2.0156 - val_accuracy: 0.4766\n",
      "Epoch 38/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8036 - accuracy: 0.5110\n",
      "Epoch 00038: val_accuracy did not improve from 0.47660\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.8036 - accuracy: 0.5110 - val_loss: 2.0589 - val_accuracy: 0.4667\n",
      "Epoch 39/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7872 - accuracy: 0.5154\n",
      "Epoch 00039: val_accuracy did not improve from 0.47660\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.7872 - accuracy: 0.5154 - val_loss: 2.1869 - val_accuracy: 0.4508\n",
      "Epoch 40/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7778 - accuracy: 0.5150\n",
      "Epoch 00040: val_accuracy did not improve from 0.47660\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.7778 - accuracy: 0.5150 - val_loss: 2.1337 - val_accuracy: 0.4622\n",
      "Epoch 41/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7501 - accuracy: 0.5264\n",
      "Epoch 00041: val_accuracy did not improve from 0.47660\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.7501 - accuracy: 0.5264 - val_loss: 2.1221 - val_accuracy: 0.4602\n",
      "Epoch 42/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7588 - accuracy: 0.5175\n",
      "Epoch 00042: val_accuracy did not improve from 0.47660\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.7588 - accuracy: 0.5175 - val_loss: 2.1030 - val_accuracy: 0.4723\n",
      "Epoch 43/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7496 - accuracy: 0.5213\n",
      "Epoch 00043: val_accuracy did not improve from 0.47660\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.7496 - accuracy: 0.5213 - val_loss: 2.0617 - val_accuracy: 0.4751\n",
      "Epoch 44/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7323 - accuracy: 0.5287\n",
      "Epoch 00044: val_accuracy improved from 0.47660 to 0.48120, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.7323 - accuracy: 0.5287 - val_loss: 2.0647 - val_accuracy: 0.4812\n",
      "Epoch 45/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7337 - accuracy: 0.5283\n",
      "Epoch 00045: val_accuracy did not improve from 0.48120\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.7337 - accuracy: 0.5283 - val_loss: 2.1475 - val_accuracy: 0.4624\n",
      "Epoch 46/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7092 - accuracy: 0.5327\n",
      "Epoch 00046: val_accuracy did not improve from 0.48120\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.7092 - accuracy: 0.5327 - val_loss: 2.0547 - val_accuracy: 0.4789\n",
      "Epoch 47/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7126 - accuracy: 0.5303\n",
      "Epoch 00047: val_accuracy did not improve from 0.48120\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.7126 - accuracy: 0.5303 - val_loss: 2.0034 - val_accuracy: 0.4801\n",
      "Epoch 48/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6933 - accuracy: 0.5332\n",
      "Epoch 00048: val_accuracy did not improve from 0.48120\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.6933 - accuracy: 0.5332 - val_loss: 2.2200 - val_accuracy: 0.4588\n",
      "Epoch 49/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6982 - accuracy: 0.5355\n",
      "Epoch 00049: val_accuracy did not improve from 0.48120\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.6982 - accuracy: 0.5355 - val_loss: 2.0718 - val_accuracy: 0.4804\n",
      "Epoch 50/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6863 - accuracy: 0.5366\n",
      "Epoch 00050: val_accuracy improved from 0.48120 to 0.48220, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.6863 - accuracy: 0.5366 - val_loss: 2.0314 - val_accuracy: 0.4822\n",
      "Epoch 51/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6623 - accuracy: 0.5433\n",
      "Epoch 00051: val_accuracy did not improve from 0.48220\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6623 - accuracy: 0.5433 - val_loss: 2.1722 - val_accuracy: 0.4630\n",
      "Epoch 52/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6557 - accuracy: 0.5432\n",
      "Epoch 00052: val_accuracy did not improve from 0.48220\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6557 - accuracy: 0.5432 - val_loss: 2.0894 - val_accuracy: 0.4777\n",
      "Epoch 53/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6494 - accuracy: 0.5456\n",
      "Epoch 00053: val_accuracy improved from 0.48220 to 0.48720, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6494 - accuracy: 0.5456 - val_loss: 2.0107 - val_accuracy: 0.4872\n",
      "Epoch 54/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6456 - accuracy: 0.5463\n",
      "Epoch 00054: val_accuracy did not improve from 0.48720\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6456 - accuracy: 0.5463 - val_loss: 2.0999 - val_accuracy: 0.4790\n",
      "Epoch 55/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6389 - accuracy: 0.5488\n",
      "Epoch 00055: val_accuracy did not improve from 0.48720\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6389 - accuracy: 0.5488 - val_loss: 2.1075 - val_accuracy: 0.4792\n",
      "Epoch 56/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6214 - accuracy: 0.5528\n",
      "Epoch 00056: val_accuracy improved from 0.48720 to 0.48840, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6214 - accuracy: 0.5528 - val_loss: 2.0011 - val_accuracy: 0.4884\n",
      "Epoch 57/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6128 - accuracy: 0.5547\n",
      "Epoch 00057: val_accuracy did not improve from 0.48840\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.6128 - accuracy: 0.5547 - val_loss: 2.1834 - val_accuracy: 0.4640\n",
      "Epoch 58/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6199 - accuracy: 0.5511\n",
      "Epoch 00058: val_accuracy did not improve from 0.48840\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6199 - accuracy: 0.5511 - val_loss: 2.0963 - val_accuracy: 0.4792\n",
      "Epoch 59/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6085 - accuracy: 0.5555\n",
      "Epoch 00059: val_accuracy improved from 0.48840 to 0.49460, saving model to InceptionNet_Adam_NoReg.hdf5\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6085 - accuracy: 0.5555 - val_loss: 1.9739 - val_accuracy: 0.4946\n",
      "Epoch 60/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6030 - accuracy: 0.5563\n",
      "Epoch 00060: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.6030 - accuracy: 0.5563 - val_loss: 2.2450 - val_accuracy: 0.4534\n",
      "Epoch 61/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5982 - accuracy: 0.5569\n",
      "Epoch 00061: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.5982 - accuracy: 0.5569 - val_loss: 2.0869 - val_accuracy: 0.4814\n",
      "Epoch 62/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5875 - accuracy: 0.5605\n",
      "Epoch 00062: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.5875 - accuracy: 0.5605 - val_loss: 2.0347 - val_accuracy: 0.4835\n",
      "Epoch 63/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5825 - accuracy: 0.5605\n",
      "Epoch 00063: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.5825 - accuracy: 0.5605 - val_loss: 1.9944 - val_accuracy: 0.4896\n",
      "Epoch 64/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5739 - accuracy: 0.5604\n",
      "Epoch 00064: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.5739 - accuracy: 0.5604 - val_loss: 2.0344 - val_accuracy: 0.4895\n",
      "Epoch 65/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5681 - accuracy: 0.5634\n",
      "Epoch 00065: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 1.5681 - accuracy: 0.5634 - val_loss: 2.0743 - val_accuracy: 0.4808\n",
      "Epoch 66/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5588 - accuracy: 0.5657\n",
      "Epoch 00066: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 1.5588 - accuracy: 0.5657 - val_loss: 2.0220 - val_accuracy: 0.4928\n",
      "Epoch 67/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5502 - accuracy: 0.5687\n",
      "Epoch 00067: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.5502 - accuracy: 0.5687 - val_loss: 2.0833 - val_accuracy: 0.4824\n",
      "Epoch 68/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5472 - accuracy: 0.5713\n",
      "Epoch 00068: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.5472 - accuracy: 0.5713 - val_loss: 2.1675 - val_accuracy: 0.4699\n",
      "Epoch 69/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5416 - accuracy: 0.5725Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.49460\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.5416 - accuracy: 0.5725 - val_loss: 2.1850 - val_accuracy: 0.4691\n",
      "Epoch 00069: early stopping\n"
     ]
    }
   ],
   "source": [
    "adam=Adam(learning_rate=0.001,clipnorm=1,name='adam')\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('InceptionNet_Adam_NoReg.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128),batch_size=128, epochs=1000, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "q9Hb3WHEYrI1",
    "outputId": "427e7e1e-8461-4840-8a20-87c21466c9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.501830042759993\n",
      "Recall: 0.4946\n",
      "Accuracy: 0.4946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "MzFPTYeEdHG4",
    "outputId": "d171ab41-a3da-40c4-9cd4-e787a50121b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to Load Weights and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "UOfTByyNhD6s",
    "outputId": "cf27563a-ece4-4eff-eab4-80d0b5fa24ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.501830042759993\n",
      "Recall: 0.4946\n",
      "Accuracy: 0.4946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation='relu')(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation='relu')(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation='relu')(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_1)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation='relu')(conv_2)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation='relu')(conv_2)\n",
    "\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation='relu')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation='relu')(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation='relu')(X)\n",
    "X = Conv2D(64, 3, activation='relu')(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "#model = create_model()\n",
    "model.load_weights('../weights/InceptionNet_Adam_NoReg.hdf5')\n",
    "\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQiMRZmkdJ2S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Inception_ADAM_NoReg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
