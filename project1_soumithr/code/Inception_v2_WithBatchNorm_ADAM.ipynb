{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hBtOqttNdJLR"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "\n",
    "#Model Creation\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = BatchNormalization(axis = 3)(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = BatchNormalization(axis = 3)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_2 = BatchNormalization(axis = 3)(conv_2)\n",
    "\n",
    "bn = BatchNormalization(axis = 3)(X)\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(bn)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = BatchNormalization(axis = 3)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_2 = BatchNormalization(axis = 3)(conv_2)\n",
    "\n",
    "bn = BatchNormalization(axis = 3)(X)\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(bn)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_11 = BatchNormalization(axis = 3)(conv_11)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_12 = BatchNormalization(axis = 3)(conv_12)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_21 = BatchNormalization(axis = 3)(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_22 = BatchNormalization(axis = 3)(conv_22)\n",
    "\n",
    "bn = BatchNormalization(axis = 3)(X)\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(bn)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation=LeakyReLU())(X)\n",
    "X = Conv2D(64, 3, activation=LeakyReLU())(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation=LeakyReLU())(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "7UqsqYEedN4b",
    "outputId": "7849754a-0206-4902-e00e-6434465ed2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.6163 - accuracy: 0.1568\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.19550, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 3.6163 - accuracy: 0.1568 - val_loss: 3.6856 - val_accuracy: 0.1955\n",
      "Epoch 2/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.9808 - accuracy: 0.2674\n",
      "Epoch 00002: val_accuracy improved from 0.19550 to 0.30700, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.9808 - accuracy: 0.2674 - val_loss: 2.7950 - val_accuracy: 0.3070\n",
      "Epoch 3/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.7079 - accuracy: 0.3189\n",
      "Epoch 00003: val_accuracy improved from 0.30700 to 0.37340, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.7079 - accuracy: 0.3189 - val_loss: 2.4739 - val_accuracy: 0.3734\n",
      "Epoch 4/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.5223 - accuracy: 0.3583\n",
      "Epoch 00004: val_accuracy improved from 0.37340 to 0.40790, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.5223 - accuracy: 0.3583 - val_loss: 2.3201 - val_accuracy: 0.4079\n",
      "Epoch 5/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.3881 - accuracy: 0.3855\n",
      "Epoch 00005: val_accuracy did not improve from 0.40790\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 2.3881 - accuracy: 0.3855 - val_loss: 2.4747 - val_accuracy: 0.3827\n",
      "Epoch 6/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.2793 - accuracy: 0.4071\n",
      "Epoch 00006: val_accuracy improved from 0.40790 to 0.40960, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 2.2793 - accuracy: 0.4071 - val_loss: 2.3031 - val_accuracy: 0.4096\n",
      "Epoch 7/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1818 - accuracy: 0.4259\n",
      "Epoch 00007: val_accuracy improved from 0.40960 to 0.43360, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 2.1818 - accuracy: 0.4259 - val_loss: 2.2001 - val_accuracy: 0.4336\n",
      "Epoch 8/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1069 - accuracy: 0.4463\n",
      "Epoch 00008: val_accuracy improved from 0.43360 to 0.49720, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 2.1069 - accuracy: 0.4463 - val_loss: 1.8960 - val_accuracy: 0.4972\n",
      "Epoch 9/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0310 - accuracy: 0.4594\n",
      "Epoch 00009: val_accuracy did not improve from 0.49720\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 2.0310 - accuracy: 0.4594 - val_loss: 2.0788 - val_accuracy: 0.4609\n",
      "Epoch 10/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9843 - accuracy: 0.4692\n",
      "Epoch 00010: val_accuracy did not improve from 0.49720\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.9843 - accuracy: 0.4692 - val_loss: 1.9554 - val_accuracy: 0.4846\n",
      "Epoch 11/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9234 - accuracy: 0.4828\n",
      "Epoch 00011: val_accuracy did not improve from 0.49720\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.9234 - accuracy: 0.4828 - val_loss: 1.9655 - val_accuracy: 0.4837\n",
      "Epoch 12/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8819 - accuracy: 0.4943\n",
      "Epoch 00012: val_accuracy did not improve from 0.49720\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.8819 - accuracy: 0.4943 - val_loss: 2.0638 - val_accuracy: 0.4645\n",
      "Epoch 13/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8392 - accuracy: 0.5028\n",
      "Epoch 00013: val_accuracy did not improve from 0.49720\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.8392 - accuracy: 0.5028 - val_loss: 1.9485 - val_accuracy: 0.4967\n",
      "Epoch 14/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7969 - accuracy: 0.5108\n",
      "Epoch 00014: val_accuracy improved from 0.49720 to 0.50600, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.7969 - accuracy: 0.5108 - val_loss: 1.8671 - val_accuracy: 0.5060\n",
      "Epoch 15/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7497 - accuracy: 0.5226\n",
      "Epoch 00015: val_accuracy did not improve from 0.50600\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.7497 - accuracy: 0.5226 - val_loss: 2.0929 - val_accuracy: 0.4673\n",
      "Epoch 16/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7210 - accuracy: 0.5283\n",
      "Epoch 00016: val_accuracy improved from 0.50600 to 0.51020, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.7210 - accuracy: 0.5283 - val_loss: 1.8580 - val_accuracy: 0.5102\n",
      "Epoch 17/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6913 - accuracy: 0.5342\n",
      "Epoch 00017: val_accuracy improved from 0.51020 to 0.54550, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 1.6913 - accuracy: 0.5342 - val_loss: 1.7149 - val_accuracy: 0.5455\n",
      "Epoch 18/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6546 - accuracy: 0.5422\n",
      "Epoch 00018: val_accuracy did not improve from 0.54550\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.6546 - accuracy: 0.5422 - val_loss: 1.7821 - val_accuracy: 0.5284\n",
      "Epoch 19/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6342 - accuracy: 0.5494\n",
      "Epoch 00019: val_accuracy did not improve from 0.54550\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.6342 - accuracy: 0.5494 - val_loss: 1.8562 - val_accuracy: 0.5149\n",
      "Epoch 20/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5984 - accuracy: 0.5558\n",
      "Epoch 00020: val_accuracy improved from 0.54550 to 0.54830, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.5984 - accuracy: 0.5558 - val_loss: 1.6878 - val_accuracy: 0.5483\n",
      "Epoch 21/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5796 - accuracy: 0.5633\n",
      "Epoch 00021: val_accuracy did not improve from 0.54830\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.5796 - accuracy: 0.5633 - val_loss: 1.8950 - val_accuracy: 0.5231\n",
      "Epoch 22/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5552 - accuracy: 0.5665\n",
      "Epoch 00022: val_accuracy did not improve from 0.54830\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.5552 - accuracy: 0.5665 - val_loss: 1.7741 - val_accuracy: 0.5420\n",
      "Epoch 23/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5348 - accuracy: 0.5747\n",
      "Epoch 00023: val_accuracy did not improve from 0.54830\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.5348 - accuracy: 0.5747 - val_loss: 1.7627 - val_accuracy: 0.5386\n",
      "Epoch 24/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5104 - accuracy: 0.5782\n",
      "Epoch 00024: val_accuracy did not improve from 0.54830\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.5104 - accuracy: 0.5782 - val_loss: 1.7303 - val_accuracy: 0.5475\n",
      "Epoch 25/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4879 - accuracy: 0.5819\n",
      "Epoch 00025: val_accuracy improved from 0.54830 to 0.57100, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.4879 - accuracy: 0.5819 - val_loss: 1.6018 - val_accuracy: 0.5710\n",
      "Epoch 26/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4738 - accuracy: 0.5900\n",
      "Epoch 00026: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.4738 - accuracy: 0.5900 - val_loss: 1.7953 - val_accuracy: 0.5330\n",
      "Epoch 27/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4517 - accuracy: 0.5938\n",
      "Epoch 00027: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.4517 - accuracy: 0.5938 - val_loss: 1.7750 - val_accuracy: 0.5405\n",
      "Epoch 28/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4303 - accuracy: 0.5961\n",
      "Epoch 00028: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.4303 - accuracy: 0.5961 - val_loss: 1.7975 - val_accuracy: 0.5305\n",
      "Epoch 29/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4105 - accuracy: 0.6022\n",
      "Epoch 00029: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.4105 - accuracy: 0.6022 - val_loss: 1.7160 - val_accuracy: 0.5500\n",
      "Epoch 30/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4027 - accuracy: 0.6032\n",
      "Epoch 00030: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.4027 - accuracy: 0.6032 - val_loss: 1.6764 - val_accuracy: 0.5513\n",
      "Epoch 31/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3782 - accuracy: 0.6102\n",
      "Epoch 00031: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.3782 - accuracy: 0.6102 - val_loss: 1.7212 - val_accuracy: 0.5589\n",
      "Epoch 32/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3612 - accuracy: 0.6146\n",
      "Epoch 00032: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.3612 - accuracy: 0.6146 - val_loss: 1.7530 - val_accuracy: 0.5440\n",
      "Epoch 33/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3484 - accuracy: 0.6173\n",
      "Epoch 00033: val_accuracy did not improve from 0.57100\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.3484 - accuracy: 0.6173 - val_loss: 1.6851 - val_accuracy: 0.5616\n",
      "Epoch 34/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3266 - accuracy: 0.6219\n",
      "Epoch 00034: val_accuracy improved from 0.57100 to 0.57880, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.3266 - accuracy: 0.6219 - val_loss: 1.6046 - val_accuracy: 0.5788\n",
      "Epoch 35/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3189 - accuracy: 0.6258\n",
      "Epoch 00035: val_accuracy did not improve from 0.57880\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.3189 - accuracy: 0.6258 - val_loss: 1.6517 - val_accuracy: 0.5607\n",
      "Epoch 36/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3092 - accuracy: 0.6256\n",
      "Epoch 00036: val_accuracy did not improve from 0.57880\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.3092 - accuracy: 0.6256 - val_loss: 1.6131 - val_accuracy: 0.5758\n",
      "Epoch 37/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2916 - accuracy: 0.6304\n",
      "Epoch 00037: val_accuracy did not improve from 0.57880\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.2916 - accuracy: 0.6304 - val_loss: 1.6283 - val_accuracy: 0.5708\n",
      "Epoch 38/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2815 - accuracy: 0.6330\n",
      "Epoch 00038: val_accuracy improved from 0.57880 to 0.59000, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.2815 - accuracy: 0.6330 - val_loss: 1.5566 - val_accuracy: 0.5900\n",
      "Epoch 39/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2704 - accuracy: 0.6363\n",
      "Epoch 00039: val_accuracy did not improve from 0.59000\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.2704 - accuracy: 0.6363 - val_loss: 1.7054 - val_accuracy: 0.5528\n",
      "Epoch 40/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2350 - accuracy: 0.6439\n",
      "Epoch 00040: val_accuracy did not improve from 0.59000\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.2350 - accuracy: 0.6439 - val_loss: 1.6236 - val_accuracy: 0.5793\n",
      "Epoch 41/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2388 - accuracy: 0.6441\n",
      "Epoch 00041: val_accuracy did not improve from 0.59000\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.2388 - accuracy: 0.6441 - val_loss: 1.6284 - val_accuracy: 0.5751\n",
      "Epoch 42/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2238 - accuracy: 0.6468\n",
      "Epoch 00042: val_accuracy improved from 0.59000 to 0.59140, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.2238 - accuracy: 0.6468 - val_loss: 1.6026 - val_accuracy: 0.5914\n",
      "Epoch 43/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2083 - accuracy: 0.6502\n",
      "Epoch 00043: val_accuracy did not improve from 0.59140\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.2083 - accuracy: 0.6502 - val_loss: 1.6579 - val_accuracy: 0.5737\n",
      "Epoch 44/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2031 - accuracy: 0.6535\n",
      "Epoch 00044: val_accuracy did not improve from 0.59140\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.2031 - accuracy: 0.6535 - val_loss: 1.6300 - val_accuracy: 0.5870\n",
      "Epoch 45/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1891 - accuracy: 0.6552\n",
      "Epoch 00045: val_accuracy improved from 0.59140 to 0.59530, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 1.1891 - accuracy: 0.6552 - val_loss: 1.5638 - val_accuracy: 0.5953\n",
      "Epoch 46/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1907 - accuracy: 0.6554\n",
      "Epoch 00046: val_accuracy improved from 0.59530 to 0.59840, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.1907 - accuracy: 0.6554 - val_loss: 1.5088 - val_accuracy: 0.5984\n",
      "Epoch 47/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1646 - accuracy: 0.6596\n",
      "Epoch 00047: val_accuracy did not improve from 0.59840\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.1646 - accuracy: 0.6596 - val_loss: 1.6484 - val_accuracy: 0.5795\n",
      "Epoch 48/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1584 - accuracy: 0.6632\n",
      "Epoch 00048: val_accuracy did not improve from 0.59840\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 1.1584 - accuracy: 0.6632 - val_loss: 1.5575 - val_accuracy: 0.5944\n",
      "Epoch 49/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1579 - accuracy: 0.6668\n",
      "Epoch 00049: val_accuracy did not improve from 0.59840\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.1579 - accuracy: 0.6668 - val_loss: 1.7177 - val_accuracy: 0.5698\n",
      "Epoch 50/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1365 - accuracy: 0.6699\n",
      "Epoch 00050: val_accuracy did not improve from 0.59840\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.1365 - accuracy: 0.6699 - val_loss: 1.7498 - val_accuracy: 0.5655\n",
      "Epoch 51/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1376 - accuracy: 0.6667\n",
      "Epoch 00051: val_accuracy did not improve from 0.59840\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.1376 - accuracy: 0.6667 - val_loss: 1.5685 - val_accuracy: 0.5936\n",
      "Epoch 52/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1237 - accuracy: 0.6704\n",
      "Epoch 00052: val_accuracy did not improve from 0.59840\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.1237 - accuracy: 0.6704 - val_loss: 1.7073 - val_accuracy: 0.5755\n",
      "Epoch 53/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1082 - accuracy: 0.6757\n",
      "Epoch 00053: val_accuracy did not improve from 0.59840\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.1082 - accuracy: 0.6757 - val_loss: 1.6302 - val_accuracy: 0.5808\n",
      "Epoch 54/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0988 - accuracy: 0.6775\n",
      "Epoch 00054: val_accuracy improved from 0.59840 to 0.60370, saving model to InceptionNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.0988 - accuracy: 0.6775 - val_loss: 1.5613 - val_accuracy: 0.6037\n",
      "Epoch 55/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0942 - accuracy: 0.6805\n",
      "Epoch 00055: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.0942 - accuracy: 0.6805 - val_loss: 1.6001 - val_accuracy: 0.5979\n",
      "Epoch 56/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0896 - accuracy: 0.6794\n",
      "Epoch 00056: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.0896 - accuracy: 0.6794 - val_loss: 1.5932 - val_accuracy: 0.5988\n",
      "Epoch 57/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0843 - accuracy: 0.6820\n",
      "Epoch 00057: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.0843 - accuracy: 0.6820 - val_loss: 1.8810 - val_accuracy: 0.5461\n",
      "Epoch 58/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0727 - accuracy: 0.6870\n",
      "Epoch 00058: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.0727 - accuracy: 0.6870 - val_loss: 1.6248 - val_accuracy: 0.5840\n",
      "Epoch 59/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0698 - accuracy: 0.6855\n",
      "Epoch 00059: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.0698 - accuracy: 0.6855 - val_loss: 1.5862 - val_accuracy: 0.6019\n",
      "Epoch 60/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0553 - accuracy: 0.6871\n",
      "Epoch 00060: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 1.0553 - accuracy: 0.6871 - val_loss: 1.6247 - val_accuracy: 0.5883\n",
      "Epoch 61/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0494 - accuracy: 0.6898\n",
      "Epoch 00061: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.0494 - accuracy: 0.6898 - val_loss: 1.7014 - val_accuracy: 0.5744\n",
      "Epoch 62/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0443 - accuracy: 0.6905\n",
      "Epoch 00062: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.0443 - accuracy: 0.6905 - val_loss: 1.6822 - val_accuracy: 0.5837\n",
      "Epoch 63/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0293 - accuracy: 0.6964\n",
      "Epoch 00063: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.0293 - accuracy: 0.6964 - val_loss: 1.7086 - val_accuracy: 0.5835\n",
      "Epoch 64/1000\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0200 - accuracy: 0.6977Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.60370\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.0200 - accuracy: 0.6977 - val_loss: 1.5931 - val_accuracy: 0.5976\n",
      "Epoch 00064: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_data=ImageDataGenerator(\n",
    "        rotation_range=20,     #randomly rotate images in the range (20 degrees)\n",
    "        horizontal_flip=True,  #randomly flip images\n",
    "        width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
    "        shear_range = 0.2,     #Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "        height_shift_range=0.1,#randomly shift images vertically (fraction of total height)\n",
    "        zoom_range=0.2,        #Range for random zoom\n",
    "        brightness_range = (0.5, 1.5))   #Range for picking a brightness shift value\n",
    "aug_data.fit(x_train)\n",
    "\n",
    "adam=Adam(learning_rate=0.001,clipnorm=1,name='adam')\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('InceptionNet_BatchNorm_Adam.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128),batch_size=128, epochs=1000, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "oolyL5qmdQC4",
    "outputId": "a6ab0b9b-d78f-4acf-feda-9d31e78c4345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6202191663168878\n",
      "Recall: 0.6037\n",
      "Accuracy: 0.6037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "wbQbvhL8p8_8",
    "outputId": "bdc34a46-cd7e-4fa7-f148-37993468b8bc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to Load Weights and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1Zo5y8riqF5M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6202191663168878\n",
      "Recall: 0.6037\n",
      "Accuracy: 0.6037\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D,MaxPool2D,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(inputs)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = BatchNormalization(axis = 3)(X)\n",
    "X = MaxPool2D((3,3), strides=(1,1), padding='same')(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = Conv2D(32, (3,3), strides = (1,1),padding='same',activation=LeakyReLU())(X)\n",
    "X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "#Inception1\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = BatchNormalization(axis = 3)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_2 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_2 = BatchNormalization(axis = 3)(conv_2)\n",
    "\n",
    "bn = BatchNormalization(axis = 3)(X)\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(bn)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception2\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_1 = BatchNormalization(axis = 3)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_2 = Conv2D(32, (1,7), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_2 = Conv2D(32, (7,1), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_2 = BatchNormalization(axis = 3)(conv_2)\n",
    "\n",
    "bn = BatchNormalization(axis = 3)(X)\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(bn)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "\n",
    "X = concatenate([conv_1,conv_2,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "#Inception3\n",
    "conv_1 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_1 = Conv2D(32, (3,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_11 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_11 = BatchNormalization(axis = 3)(conv_11)\n",
    "conv_12 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU())(conv_1)\n",
    "conv_12 = BatchNormalization(axis = 3)(conv_12)\n",
    "\n",
    "conv_2 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "conv_21 = Conv2D(32, (1,3), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_21 = BatchNormalization(axis = 3)(conv_21)\n",
    "conv_22 = Conv2D(32, (3,1), padding='same', activation=LeakyReLU())(conv_2)\n",
    "conv_22 = BatchNormalization(axis = 3)(conv_22)\n",
    "\n",
    "bn = BatchNormalization(axis = 3)(X)\n",
    "conv_3 = MaxPool2D((3,3), strides=(1,1), padding='same')(bn)\n",
    "conv_3 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(32, (1,1), padding='same', activation=LeakyReLU())(X)\n",
    "\n",
    "X = concatenate([conv_11,conv_12,conv_21,conv_22,conv_3,conv_4], axis=3)\n",
    "\n",
    "\n",
    "X = Conv2D(32, 3, activation=LeakyReLU())(X)\n",
    "X = Conv2D(64, 3, activation=LeakyReLU())(X)\n",
    "X = AveragePooling2D(4)(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation=LeakyReLU())(X)\n",
    "outputs = Dense(100, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model.load_weights('../weights/InceptionNet_BatchNorm_Adam.hdf5')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Inception_BatchNorm_ADAM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
