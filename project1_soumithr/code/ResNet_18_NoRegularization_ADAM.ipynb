{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NtOdPt3W9cQ7"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    #bn = BatchNormalization()(relu)\n",
    "    return relu\n",
    "\n",
    "#Defining Residual Block\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "#Defining ResNet Block\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "    \n",
    "    #t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(inputs)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2, 2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    adam=Adam(learning_rate=0.0001,clipnorm=1,name='adam')\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet taken and modified from https://towardsdatascience.com/building-a-resnet-in-keras-e8f1322a49ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "WkFE27N8Gn1O",
    "outputId": "03d0bdcf-ca1c-4d5f-90e5-cccb785c2407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 32, 32, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 32, 32, 64)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 64)   0           re_lu_17[0][0]                   \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 32, 32, 64)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 32, 32, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 64)   0           re_lu_19[0][0]                   \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 32, 32, 64)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 128)  73856       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 16, 16, 128)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 128)  8320        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 16, 16, 128)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 16, 16, 128)  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           re_lu_23[0][0]                   \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 16, 16, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 256)    295168      re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 8, 8, 256)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           conv2d_32[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 8, 8, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 8, 8, 256)    0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           re_lu_27[0][0]                   \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 8, 8, 256)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 512)    1180160     re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 4, 4, 512)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 4, 4, 512)    131584      re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 512)    0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 4, 4, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 4, 4, 512)    0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           re_lu_31[0][0]                   \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 4, 4, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          51300       dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,477,988\n",
      "Trainable params: 11,477,988\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.2741 - accuracy: 0.0901\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.15110, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 4.2741 - accuracy: 0.0901 - val_loss: 3.6455 - val_accuracy: 0.1511\n",
      "Epoch 2/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.5178 - accuracy: 0.1722\n",
      "Epoch 00002: val_accuracy improved from 0.15110 to 0.20580, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 3.5178 - accuracy: 0.1722 - val_loss: 3.2827 - val_accuracy: 0.2058\n",
      "Epoch 3/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.2212 - accuracy: 0.2261\n",
      "Epoch 00003: val_accuracy improved from 0.20580 to 0.26100, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 3.2212 - accuracy: 0.2261 - val_loss: 3.0360 - val_accuracy: 0.2610\n",
      "Epoch 4/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.0113 - accuracy: 0.2661\n",
      "Epoch 00004: val_accuracy improved from 0.26100 to 0.30320, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 3.0113 - accuracy: 0.2661 - val_loss: 2.8399 - val_accuracy: 0.3032\n",
      "Epoch 5/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.8341 - accuracy: 0.3026\n",
      "Epoch 00005: val_accuracy improved from 0.30320 to 0.33470, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 53s 137ms/step - loss: 2.8341 - accuracy: 0.3026 - val_loss: 2.6427 - val_accuracy: 0.3347\n",
      "Epoch 6/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.6903 - accuracy: 0.3298\n",
      "Epoch 00006: val_accuracy improved from 0.33470 to 0.35260, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 2.6903 - accuracy: 0.3298 - val_loss: 2.5677 - val_accuracy: 0.3526\n",
      "Epoch 7/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.5622 - accuracy: 0.3585\n",
      "Epoch 00007: val_accuracy improved from 0.35260 to 0.37300, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 2.5622 - accuracy: 0.3585 - val_loss: 2.5045 - val_accuracy: 0.3730\n",
      "Epoch 8/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.4179 - accuracy: 0.3868\n",
      "Epoch 00008: val_accuracy improved from 0.37300 to 0.38340, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 2.4179 - accuracy: 0.3868 - val_loss: 2.4097 - val_accuracy: 0.3834\n",
      "Epoch 9/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.3106 - accuracy: 0.4092\n",
      "Epoch 00009: val_accuracy improved from 0.38340 to 0.42240, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 53s 137ms/step - loss: 2.3106 - accuracy: 0.4092 - val_loss: 2.2321 - val_accuracy: 0.4224\n",
      "Epoch 10/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.2028 - accuracy: 0.4338\n",
      "Epoch 00010: val_accuracy improved from 0.42240 to 0.43420, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 2.2028 - accuracy: 0.4338 - val_loss: 2.2177 - val_accuracy: 0.4342\n",
      "Epoch 11/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1040 - accuracy: 0.4550\n",
      "Epoch 00011: val_accuracy improved from 0.43420 to 0.43730, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 2.1040 - accuracy: 0.4550 - val_loss: 2.1943 - val_accuracy: 0.4373\n",
      "Epoch 12/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0010 - accuracy: 0.4778\n",
      "Epoch 00012: val_accuracy improved from 0.43730 to 0.45830, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 2.0010 - accuracy: 0.4778 - val_loss: 2.1399 - val_accuracy: 0.4583\n",
      "Epoch 13/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9183 - accuracy: 0.4946\n",
      "Epoch 00013: val_accuracy improved from 0.45830 to 0.46850, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 1.9183 - accuracy: 0.4946 - val_loss: 2.0828 - val_accuracy: 0.4685\n",
      "Epoch 14/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8443 - accuracy: 0.5143\n",
      "Epoch 00014: val_accuracy improved from 0.46850 to 0.47080, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 1.8443 - accuracy: 0.5143 - val_loss: 2.0847 - val_accuracy: 0.4708\n",
      "Epoch 15/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7712 - accuracy: 0.5302\n",
      "Epoch 00015: val_accuracy improved from 0.47080 to 0.49050, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 1.7712 - accuracy: 0.5302 - val_loss: 1.9964 - val_accuracy: 0.4905\n",
      "Epoch 16/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6873 - accuracy: 0.5486\n",
      "Epoch 00016: val_accuracy did not improve from 0.49050\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 1.6873 - accuracy: 0.5486 - val_loss: 2.1033 - val_accuracy: 0.4770\n",
      "Epoch 17/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6130 - accuracy: 0.5678\n",
      "Epoch 00017: val_accuracy improved from 0.49050 to 0.50510, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 1.6130 - accuracy: 0.5678 - val_loss: 2.0207 - val_accuracy: 0.5051\n",
      "Epoch 18/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5463 - accuracy: 0.5814\n",
      "Epoch 00018: val_accuracy did not improve from 0.50510\n",
      "391/391 [==============================] - 54s 137ms/step - loss: 1.5463 - accuracy: 0.5814 - val_loss: 1.9920 - val_accuracy: 0.5041\n",
      "Epoch 19/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4884 - accuracy: 0.5969\n",
      "Epoch 00019: val_accuracy improved from 0.50510 to 0.51190, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 1.4884 - accuracy: 0.5969 - val_loss: 1.9417 - val_accuracy: 0.5119\n",
      "Epoch 20/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4212 - accuracy: 0.6115\n",
      "Epoch 00020: val_accuracy did not improve from 0.51190\n",
      "391/391 [==============================] - 53s 137ms/step - loss: 1.4212 - accuracy: 0.6115 - val_loss: 1.9917 - val_accuracy: 0.5096\n",
      "Epoch 21/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3559 - accuracy: 0.6279\n",
      "Epoch 00021: val_accuracy improved from 0.51190 to 0.52130, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 1.3559 - accuracy: 0.6279 - val_loss: 1.9103 - val_accuracy: 0.5213\n",
      "Epoch 22/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3122 - accuracy: 0.6352\n",
      "Epoch 00022: val_accuracy did not improve from 0.52130\n",
      "391/391 [==============================] - 53s 136ms/step - loss: 1.3122 - accuracy: 0.6352 - val_loss: 1.9788 - val_accuracy: 0.5159\n",
      "Epoch 23/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2493 - accuracy: 0.6519\n",
      "Epoch 00023: val_accuracy did not improve from 0.52130\n",
      "391/391 [==============================] - 53s 136ms/step - loss: 1.2493 - accuracy: 0.6519 - val_loss: 2.0344 - val_accuracy: 0.5143\n",
      "Epoch 24/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1901 - accuracy: 0.6671\n",
      "Epoch 00024: val_accuracy improved from 0.52130 to 0.52750, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 53s 137ms/step - loss: 1.1901 - accuracy: 0.6671 - val_loss: 1.9826 - val_accuracy: 0.5275\n",
      "Epoch 25/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1448 - accuracy: 0.6778\n",
      "Epoch 00025: val_accuracy did not improve from 0.52750\n",
      "391/391 [==============================] - 53s 137ms/step - loss: 1.1448 - accuracy: 0.6778 - val_loss: 2.1338 - val_accuracy: 0.5234\n",
      "Epoch 26/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.6933\n",
      "Epoch 00026: val_accuracy did not improve from 0.52750\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 1.0892 - accuracy: 0.6933 - val_loss: 2.0510 - val_accuracy: 0.5214\n",
      "Epoch 27/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0523 - accuracy: 0.7034\n",
      "Epoch 00027: val_accuracy improved from 0.52750 to 0.52790, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 55s 139ms/step - loss: 1.0523 - accuracy: 0.7034 - val_loss: 2.0152 - val_accuracy: 0.5279\n",
      "Epoch 28/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.7166\n",
      "Epoch 00028: val_accuracy improved from 0.52790 to 0.53260, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 0.9989 - accuracy: 0.7166 - val_loss: 2.0845 - val_accuracy: 0.5326\n",
      "Epoch 29/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9556 - accuracy: 0.7265\n",
      "Epoch 00029: val_accuracy improved from 0.53260 to 0.53770, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.9556 - accuracy: 0.7265 - val_loss: 2.1397 - val_accuracy: 0.5377\n",
      "Epoch 30/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9189 - accuracy: 0.7338\n",
      "Epoch 00030: val_accuracy did not improve from 0.53770\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.9189 - accuracy: 0.7338 - val_loss: 2.0253 - val_accuracy: 0.5348\n",
      "Epoch 31/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.7437\n",
      "Epoch 00031: val_accuracy did not improve from 0.53770\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.8852 - accuracy: 0.7437 - val_loss: 2.3096 - val_accuracy: 0.5284\n",
      "Epoch 32/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8436 - accuracy: 0.7556\n",
      "Epoch 00032: val_accuracy did not improve from 0.53770\n",
      "391/391 [==============================] - 54s 138ms/step - loss: 0.8436 - accuracy: 0.7556 - val_loss: 2.2507 - val_accuracy: 0.5337\n",
      "Epoch 33/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8123 - accuracy: 0.7613\n",
      "Epoch 00033: val_accuracy improved from 0.53770 to 0.55010, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.8123 - accuracy: 0.7613 - val_loss: 2.1203 - val_accuracy: 0.5501\n",
      "Epoch 34/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7749 - accuracy: 0.7743\n",
      "Epoch 00034: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.7749 - accuracy: 0.7743 - val_loss: 2.1755 - val_accuracy: 0.5384\n",
      "Epoch 35/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7403 - accuracy: 0.7844\n",
      "Epoch 00035: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.7403 - accuracy: 0.7844 - val_loss: 2.3348 - val_accuracy: 0.5358\n",
      "Epoch 36/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7109 - accuracy: 0.7914\n",
      "Epoch 00036: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.7109 - accuracy: 0.7914 - val_loss: 2.2004 - val_accuracy: 0.5499\n",
      "Epoch 37/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6840 - accuracy: 0.7983\n",
      "Epoch 00037: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.6840 - accuracy: 0.7983 - val_loss: 2.2968 - val_accuracy: 0.5448\n",
      "Epoch 38/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.8074\n",
      "Epoch 00038: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.6543 - accuracy: 0.8074 - val_loss: 2.3793 - val_accuracy: 0.5445\n",
      "Epoch 39/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.8128\n",
      "Epoch 00039: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.6305 - accuracy: 0.8128 - val_loss: 2.5315 - val_accuracy: 0.5356\n",
      "Epoch 40/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6045 - accuracy: 0.8201\n",
      "Epoch 00040: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.6045 - accuracy: 0.8201 - val_loss: 2.5333 - val_accuracy: 0.5386\n",
      "Epoch 41/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.8265\n",
      "Epoch 00041: val_accuracy did not improve from 0.55010\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.5843 - accuracy: 0.8265 - val_loss: 2.5102 - val_accuracy: 0.5391\n",
      "Epoch 42/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.8320\n",
      "Epoch 00042: val_accuracy improved from 0.55010 to 0.55350, saving model to ResNet_Basic_Adam.hdf5\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 0.5664 - accuracy: 0.8320 - val_loss: 2.4800 - val_accuracy: 0.5535\n",
      "Epoch 43/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.8395\n",
      "Epoch 00043: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 55s 139ms/step - loss: 0.5392 - accuracy: 0.8395 - val_loss: 2.3424 - val_accuracy: 0.5512\n",
      "Epoch 44/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.8455\n",
      "Epoch 00044: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 0.5167 - accuracy: 0.8455 - val_loss: 2.5898 - val_accuracy: 0.5390\n",
      "Epoch 45/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5024 - accuracy: 0.8501\n",
      "Epoch 00045: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.5024 - accuracy: 0.8501 - val_loss: 2.6064 - val_accuracy: 0.5336\n",
      "Epoch 46/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4885 - accuracy: 0.8531\n",
      "Epoch 00046: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 0.4885 - accuracy: 0.8531 - val_loss: 2.6311 - val_accuracy: 0.5364\n",
      "Epoch 47/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4678 - accuracy: 0.8593\n",
      "Epoch 00047: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.4678 - accuracy: 0.8593 - val_loss: 2.6692 - val_accuracy: 0.5377\n",
      "Epoch 48/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.8602\n",
      "Epoch 00048: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 0.4665 - accuracy: 0.8602 - val_loss: 2.6469 - val_accuracy: 0.5444\n",
      "Epoch 49/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.8673\n",
      "Epoch 00049: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 0.4408 - accuracy: 0.8673 - val_loss: 2.6339 - val_accuracy: 0.5427\n",
      "Epoch 50/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4294 - accuracy: 0.8695\n",
      "Epoch 00050: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.4294 - accuracy: 0.8695 - val_loss: 2.8881 - val_accuracy: 0.5297\n",
      "Epoch 51/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4198 - accuracy: 0.8749\n",
      "Epoch 00051: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 54s 139ms/step - loss: 0.4198 - accuracy: 0.8749 - val_loss: 2.6936 - val_accuracy: 0.5456\n",
      "Epoch 52/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8779Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.55350\n",
      "391/391 [==============================] - 55s 140ms/step - loss: 0.4083 - accuracy: 0.8779 - val_loss: 2.8108 - val_accuracy: 0.5488\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net()\n",
    "model.summary()\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_data=ImageDataGenerator(\n",
    "        rotation_range=20,     #randomly rotate images in the range (20 degrees)\n",
    "        horizontal_flip=True,  #randomly flip images\n",
    "        width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
    "        shear_range = 0.2,     #Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "        height_shift_range=0.1,#randomly shift images vertically (fraction of total height)\n",
    "        zoom_range=0.2,        #Range for random zoom\n",
    "        brightness_range = (0.5, 1.5))   #Range for picking a brightness shift value\n",
    "aug_data.fit(x_train)\n",
    "\n",
    "# save model after each epoch\n",
    "checkpoint = ModelCheckpoint(\"ResNet_Basic_Adam.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128), batch_size=128, epochs=70, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "CJHdIu0MGvkC",
    "outputId": "577f8158-a5c3-4405-ab41-8437bea1bf70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.5740739259190092\n",
      "Recall: 0.5535\n",
      "Accuracy: 0.5535\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "3Gr1Z1vPgqen",
    "outputId": "2929509e-ab03-492c-ff6b-136ccffdaf04"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to Load Weights and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fv0GUQZSgtrR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.5740739259190092\n",
      "Recall: 0.5535\n",
      "Accuracy: 0.5535\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    #bn = BatchNormalization()(relu)\n",
    "    return relu\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "    \n",
    "    #t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(inputs)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2, 2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    adam=Adam(learning_rate=0.0001,clipnorm=1,name='adam')\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net() # or create_plain_net()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights('../weights/ResNet_Basic_Adam.hdf5')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_Basic_Adam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
