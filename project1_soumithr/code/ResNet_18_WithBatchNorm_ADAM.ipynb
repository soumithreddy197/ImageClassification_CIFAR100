{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4zqgQb42X5cm"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "#Creating Model\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2, 2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t=Dense(512,activation='relu')(t)\n",
    "    t=BatchNormalization()(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    adam=Adam(learning_rate=0.001,clipnorm=1,name='adam')\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet taken and modified from https://towardsdatascience.com/building-a-resnet-in-keras-e8f1322a49ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "RWZj9aGDX_Pe",
    "outputId": "d0629e34-1828-4fe7-bbdf-7706d31f8c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 3)    12          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 64)   1792        batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 32, 32, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 32, 32, 64)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 64)   0           batch_normalization_20[0][0]     \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 32, 32, 64)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 32, 32, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 64)   0           batch_normalization_22[0][0]     \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 32, 32, 64)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 128)  73856       batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 16, 16, 128)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 128)  8320        batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 16, 16, 128)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 128)  512         re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 16, 16, 128)  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 128)  512         re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  147584      batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           batch_normalization_26[0][0]     \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 16, 16, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 128)  512         re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 256)    295168      batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 8, 8, 256)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 256)    33024       batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           conv2d_32[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 8, 8, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 8, 8, 256)    0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 256)    1024        re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           batch_normalization_30[0][0]     \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 8, 8, 256)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 256)    1024        re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 512)    1180160     batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 4, 4, 512)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 4, 4, 512)    2048        re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 4, 4, 512)    131584      batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 512)    0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 4, 4, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 4, 4, 512)    2048        re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 4, 4, 512)    0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 4, 4, 512)    2048        re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           batch_normalization_34[0][0]     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 4, 4, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 4, 4, 512)    2048        re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          51300       batch_normalization_37[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 11,495,664\n",
      "Trainable params: 11,486,826\n",
      "Non-trainable params: 8,838\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.0747 - accuracy: 0.0813\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.08740, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 136ms/step - loss: 4.0747 - accuracy: 0.0813 - val_loss: 4.6338 - val_accuracy: 0.0874\n",
      "Epoch 2/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.5752 - accuracy: 0.1494\n",
      "Epoch 00002: val_accuracy improved from 0.08740 to 0.17030, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 3.5752 - accuracy: 0.1494 - val_loss: 3.8377 - val_accuracy: 0.1703\n",
      "Epoch 3/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.2218 - accuracy: 0.2091\n",
      "Epoch 00003: val_accuracy improved from 0.17030 to 0.20660, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 3.2218 - accuracy: 0.2091 - val_loss: 3.6111 - val_accuracy: 0.2066\n",
      "Epoch 4/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.9066 - accuracy: 0.2648\n",
      "Epoch 00004: val_accuracy improved from 0.20660 to 0.30010, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 136ms/step - loss: 2.9066 - accuracy: 0.2648 - val_loss: 2.7138 - val_accuracy: 0.3001\n",
      "Epoch 5/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.6798 - accuracy: 0.3109\n",
      "Epoch 00005: val_accuracy improved from 0.30010 to 0.33620, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 2.6798 - accuracy: 0.3109 - val_loss: 2.6428 - val_accuracy: 0.3362\n",
      "Epoch 6/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.4151 - accuracy: 0.3654\n",
      "Epoch 00006: val_accuracy improved from 0.33620 to 0.39560, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 2.4151 - accuracy: 0.3654 - val_loss: 2.2697 - val_accuracy: 0.3956\n",
      "Epoch 7/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.2395 - accuracy: 0.4021\n",
      "Epoch 00007: val_accuracy improved from 0.39560 to 0.44180, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 2.2395 - accuracy: 0.4021 - val_loss: 2.1612 - val_accuracy: 0.4418\n",
      "Epoch 8/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0630 - accuracy: 0.4432\n",
      "Epoch 00008: val_accuracy improved from 0.44180 to 0.44810, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 2.0630 - accuracy: 0.4432 - val_loss: 2.1695 - val_accuracy: 0.4481\n",
      "Epoch 9/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9279 - accuracy: 0.4760\n",
      "Epoch 00009: val_accuracy improved from 0.44810 to 0.47550, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 136ms/step - loss: 1.9279 - accuracy: 0.4760 - val_loss: 2.2110 - val_accuracy: 0.4755\n",
      "Epoch 10/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7982 - accuracy: 0.5050\n",
      "Epoch 00010: val_accuracy improved from 0.47550 to 0.51450, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 137ms/step - loss: 1.7982 - accuracy: 0.5050 - val_loss: 1.8145 - val_accuracy: 0.5145\n",
      "Epoch 11/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7059 - accuracy: 0.5283\n",
      "Epoch 00011: val_accuracy improved from 0.51450 to 0.52910, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 136ms/step - loss: 1.7059 - accuracy: 0.5283 - val_loss: 1.7169 - val_accuracy: 0.5291\n",
      "Epoch 12/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6201 - accuracy: 0.5507\n",
      "Epoch 00012: val_accuracy did not improve from 0.52910\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 1.6201 - accuracy: 0.5507 - val_loss: 2.0940 - val_accuracy: 0.4808\n",
      "Epoch 13/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5913 - accuracy: 0.5555\n",
      "Epoch 00013: val_accuracy improved from 0.52910 to 0.53360, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 53s 135ms/step - loss: 1.5913 - accuracy: 0.5555 - val_loss: 1.7425 - val_accuracy: 0.5336\n",
      "Epoch 14/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4631 - accuracy: 0.5846\n",
      "Epoch 00014: val_accuracy improved from 0.53360 to 0.54150, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 134ms/step - loss: 1.4631 - accuracy: 0.5846 - val_loss: 1.8782 - val_accuracy: 0.5415\n",
      "Epoch 15/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3638 - accuracy: 0.6097\n",
      "Epoch 00015: val_accuracy improved from 0.54150 to 0.58190, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 1.3638 - accuracy: 0.6097 - val_loss: 1.5783 - val_accuracy: 0.5819\n",
      "Epoch 16/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2863 - accuracy: 0.6275\n",
      "Epoch 00016: val_accuracy did not improve from 0.58190\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 1.2863 - accuracy: 0.6275 - val_loss: 2.0975 - val_accuracy: 0.5718\n",
      "Epoch 17/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2231 - accuracy: 0.6415\n",
      "Epoch 00017: val_accuracy improved from 0.58190 to 0.58220, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 1.2231 - accuracy: 0.6415 - val_loss: 5.5055 - val_accuracy: 0.5822\n",
      "Epoch 18/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1684 - accuracy: 0.6584\n",
      "Epoch 00018: val_accuracy improved from 0.58220 to 0.58320, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 1.1684 - accuracy: 0.6584 - val_loss: 1.6993 - val_accuracy: 0.5832\n",
      "Epoch 19/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1043 - accuracy: 0.6739\n",
      "Epoch 00019: val_accuracy did not improve from 0.58320\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 1.1043 - accuracy: 0.6739 - val_loss: 2.9811 - val_accuracy: 0.5803\n",
      "Epoch 20/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0615 - accuracy: 0.6849\n",
      "Epoch 00020: val_accuracy improved from 0.58320 to 0.59310, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 1.0615 - accuracy: 0.6849 - val_loss: 3.0804 - val_accuracy: 0.5931\n",
      "Epoch 21/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0030 - accuracy: 0.6986\n",
      "Epoch 00021: val_accuracy did not improve from 0.59310\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 1.0030 - accuracy: 0.6986 - val_loss: 1.8463 - val_accuracy: 0.5890\n",
      "Epoch 22/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9588 - accuracy: 0.7136\n",
      "Epoch 00022: val_accuracy improved from 0.59310 to 0.60570, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 134ms/step - loss: 0.9588 - accuracy: 0.7136 - val_loss: 1.5498 - val_accuracy: 0.6057\n",
      "Epoch 23/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9093 - accuracy: 0.7242\n",
      "Epoch 00023: val_accuracy improved from 0.60570 to 0.62240, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 0.9093 - accuracy: 0.7242 - val_loss: 1.5025 - val_accuracy: 0.6224\n",
      "Epoch 24/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8718 - accuracy: 0.7336\n",
      "Epoch 00024: val_accuracy did not improve from 0.62240\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.8718 - accuracy: 0.7336 - val_loss: 1.7528 - val_accuracy: 0.6038\n",
      "Epoch 25/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8250 - accuracy: 0.7486\n",
      "Epoch 00025: val_accuracy did not improve from 0.62240\n",
      "391/391 [==============================] - 51s 132ms/step - loss: 0.8250 - accuracy: 0.7486 - val_loss: 1.5586 - val_accuracy: 0.6074\n",
      "Epoch 26/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7870 - accuracy: 0.7590\n",
      "Epoch 00026: val_accuracy did not improve from 0.62240\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.7870 - accuracy: 0.7590 - val_loss: 1.6701 - val_accuracy: 0.6197\n",
      "Epoch 27/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7497 - accuracy: 0.7699\n",
      "Epoch 00027: val_accuracy improved from 0.62240 to 0.62610, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 0.7497 - accuracy: 0.7699 - val_loss: 1.4973 - val_accuracy: 0.6261\n",
      "Epoch 28/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7185 - accuracy: 0.7767\n",
      "Epoch 00028: val_accuracy did not improve from 0.62610\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.7185 - accuracy: 0.7767 - val_loss: 1.7358 - val_accuracy: 0.6228\n",
      "Epoch 29/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.7860\n",
      "Epoch 00029: val_accuracy did not improve from 0.62610\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.6817 - accuracy: 0.7860 - val_loss: 1.9309 - val_accuracy: 0.6033\n",
      "Epoch 30/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6548 - accuracy: 0.7943\n",
      "Epoch 00030: val_accuracy improved from 0.62610 to 0.63580, saving model to ResNet_BatchNorm_Adam.hdf5\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.6548 - accuracy: 0.7943 - val_loss: 1.6071 - val_accuracy: 0.6358\n",
      "Epoch 31/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6214 - accuracy: 0.8038\n",
      "Epoch 00031: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.6214 - accuracy: 0.8038 - val_loss: 2.7680 - val_accuracy: 0.6201\n",
      "Epoch 32/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.8116\n",
      "Epoch 00032: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.6059 - accuracy: 0.8116 - val_loss: 4.0186 - val_accuracy: 0.6187\n",
      "Epoch 33/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.8233\n",
      "Epoch 00033: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.5652 - accuracy: 0.8233 - val_loss: 3.0570 - val_accuracy: 0.6193\n",
      "Epoch 34/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5435 - accuracy: 0.8287\n",
      "Epoch 00034: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.5435 - accuracy: 0.8287 - val_loss: 1.8121 - val_accuracy: 0.6191\n",
      "Epoch 35/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.8316\n",
      "Epoch 00035: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.5308 - accuracy: 0.8316 - val_loss: 1.6429 - val_accuracy: 0.6244\n",
      "Epoch 36/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8377\n",
      "Epoch 00036: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.5089 - accuracy: 0.8377 - val_loss: 1.6039 - val_accuracy: 0.6314\n",
      "Epoch 37/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.8420\n",
      "Epoch 00037: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.4975 - accuracy: 0.8420 - val_loss: 1.7628 - val_accuracy: 0.6104\n",
      "Epoch 38/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.8520\n",
      "Epoch 00038: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.4625 - accuracy: 0.8520 - val_loss: 1.7138 - val_accuracy: 0.6312\n",
      "Epoch 39/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.8551\n",
      "Epoch 00039: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.4554 - accuracy: 0.8551 - val_loss: 1.6788 - val_accuracy: 0.6283\n",
      "Epoch 40/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8608Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.63580\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.4331 - accuracy: 0.8608 - val_loss: 1.6714 - val_accuracy: 0.6318\n",
      "Epoch 00040: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net() \n",
    "model.summary()\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_data=ImageDataGenerator(\n",
    "        rotation_range=20,     #randomly rotate images in the range (20 degrees)\n",
    "        horizontal_flip=True,  #randomly flip images\n",
    "        width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
    "        shear_range = 0.2,     #Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "        height_shift_range=0.1,#randomly shift images vertically (fraction of total height)\n",
    "        zoom_range=0.2,        #Range for random zoom\n",
    "        brightness_range = (0.5, 1.5))   #Range for picking a brightness shift value\n",
    "aug_data.fit(x_train)\n",
    "\n",
    "# save model after each epoch\n",
    "checkpoint = ModelCheckpoint(\"ResNet_BatchNorm_Adam.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128), batch_size=128, epochs=70, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "bTB7OFZUYBuZ",
    "outputId": "56680f95-7db1-4fdd-a3a7-4d4622f2a24a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6523166103497637\n",
      "Recall: 0.6358\n",
      "Accuracy: 0.6358\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "_O-U_AJpgnHK",
    "outputId": "03b2bb64-9764-440f-97e7-f43d4ebf41c1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to Load Weights and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hke41fqNgpBA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6523166103497637\n",
      "Recall: 0.6358\n",
      "Accuracy: 0.6358\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2, 2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t=Dense(512,activation='relu')(t)\n",
    "    t=BatchNormalization()(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    adam=Adam(learning_rate=0.001,clipnorm=1,name='adam')\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net() \n",
    "model.load_weights('../weights/ResNet_BatchNorm_Adam.hdf5')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNet_Batch_Adam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
