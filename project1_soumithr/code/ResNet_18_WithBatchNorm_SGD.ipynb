{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FSnavq6g3uSG"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "#Creating Model\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2,2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    t = BatchNormalization()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    t = BatchNormalization()(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    sgd=SGD(learning_rate=0.01,clipnorm=1,momentum=0.9,name='sgd')\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet taken and modified from https://towardsdatascience.com/building-a-resnet-in-keras-e8f1322a49ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "xXqAp2Dw35ky",
    "outputId": "7eac0dea-9465-4d55-fd3d-e08234e1cc1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 3)    12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   1792        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 32, 32, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   36928       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 32, 32, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 32, 32, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36928       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 128)  73856       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 16, 16, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 128)  8320        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 128)  147584      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 128)  0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 16, 16, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  147584      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 128)  512         re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 128)  147584      batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           batch_normalization_7[0][0]      \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 16, 16, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 256)    295168      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 8, 8, 256)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 256)    1024        re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 256)    33024       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 256)    0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 8, 8, 256)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 256)    1024        re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 8, 8, 256)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 256)    590080      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 256)    0           batch_normalization_11[0][0]     \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 8, 8, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 512)    1180160     batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 4, 4, 512)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 512)    2048        re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 512)    131584      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 512)    2048        re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 4, 4, 512)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 512)    2048        re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 512)    2359808     batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 512)    0           batch_normalization_15[0][0]     \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 4, 4, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 512)    2048        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 512)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          51300       batch_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 11,760,368\n",
      "Trainable params: 11,750,506\n",
      "Non-trainable params: 9,862\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.1156 - accuracy: 0.0890\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.14980, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 4.1156 - accuracy: 0.0890 - val_loss: 3.6470 - val_accuracy: 0.1498\n",
      "Epoch 2/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.3885 - accuracy: 0.1900\n",
      "Epoch 00002: val_accuracy improved from 0.14980 to 0.22720, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 3.3885 - accuracy: 0.1900 - val_loss: 3.1483 - val_accuracy: 0.2272\n",
      "Epoch 3/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.9912 - accuracy: 0.2592\n",
      "Epoch 00003: val_accuracy improved from 0.22720 to 0.31010, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 2.9912 - accuracy: 0.2592 - val_loss: 2.7398 - val_accuracy: 0.3101\n",
      "Epoch 4/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.6440 - accuracy: 0.3260\n",
      "Epoch 00004: val_accuracy improved from 0.31010 to 0.36570, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 2.6440 - accuracy: 0.3260 - val_loss: 2.4727 - val_accuracy: 0.3657\n",
      "Epoch 5/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.3715 - accuracy: 0.3802\n",
      "Epoch 00005: val_accuracy improved from 0.36570 to 0.41420, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 2.3715 - accuracy: 0.3802 - val_loss: 2.2407 - val_accuracy: 0.4142\n",
      "Epoch 6/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1615 - accuracy: 0.4246\n",
      "Epoch 00006: val_accuracy improved from 0.41420 to 0.44230, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 2.1615 - accuracy: 0.4246 - val_loss: 2.1221 - val_accuracy: 0.4423\n",
      "Epoch 7/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9925 - accuracy: 0.4632\n",
      "Epoch 00007: val_accuracy improved from 0.44230 to 0.47270, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.9925 - accuracy: 0.4632 - val_loss: 2.0240 - val_accuracy: 0.4727\n",
      "Epoch 8/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8393 - accuracy: 0.4960\n",
      "Epoch 00008: val_accuracy improved from 0.47270 to 0.49620, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.8393 - accuracy: 0.4960 - val_loss: 1.8624 - val_accuracy: 0.4962\n",
      "Epoch 9/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7149 - accuracy: 0.5276\n",
      "Epoch 00009: val_accuracy did not improve from 0.49620\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.7149 - accuracy: 0.5276 - val_loss: 1.8787 - val_accuracy: 0.4957\n",
      "Epoch 10/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6062 - accuracy: 0.5519\n",
      "Epoch 00010: val_accuracy improved from 0.49620 to 0.52790, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.6062 - accuracy: 0.5519 - val_loss: 1.7805 - val_accuracy: 0.5279\n",
      "Epoch 11/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5066 - accuracy: 0.5736\n",
      "Epoch 00011: val_accuracy improved from 0.52790 to 0.54160, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.5066 - accuracy: 0.5736 - val_loss: 1.7031 - val_accuracy: 0.5416\n",
      "Epoch 12/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4336 - accuracy: 0.5925\n",
      "Epoch 00012: val_accuracy improved from 0.54160 to 0.54920, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.4336 - accuracy: 0.5925 - val_loss: 1.7013 - val_accuracy: 0.5492\n",
      "Epoch 13/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3483 - accuracy: 0.6142\n",
      "Epoch 00013: val_accuracy improved from 0.54920 to 0.56410, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.3483 - accuracy: 0.6142 - val_loss: 1.6262 - val_accuracy: 0.5641\n",
      "Epoch 14/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2720 - accuracy: 0.6331\n",
      "Epoch 00014: val_accuracy improved from 0.56410 to 0.57440, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.2720 - accuracy: 0.6331 - val_loss: 1.5610 - val_accuracy: 0.5744\n",
      "Epoch 15/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2192 - accuracy: 0.6474\n",
      "Epoch 00015: val_accuracy improved from 0.57440 to 0.58860, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.2192 - accuracy: 0.6474 - val_loss: 1.5473 - val_accuracy: 0.5886\n",
      "Epoch 16/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1492 - accuracy: 0.6623\n",
      "Epoch 00016: val_accuracy did not improve from 0.58860\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.1492 - accuracy: 0.6623 - val_loss: 1.5894 - val_accuracy: 0.5798\n",
      "Epoch 17/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1017 - accuracy: 0.6761\n",
      "Epoch 00017: val_accuracy did not improve from 0.58860\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 1.1017 - accuracy: 0.6761 - val_loss: 1.6377 - val_accuracy: 0.5745\n",
      "Epoch 18/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0483 - accuracy: 0.6904\n",
      "Epoch 00018: val_accuracy improved from 0.58860 to 0.60240, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 1.0483 - accuracy: 0.6904 - val_loss: 1.5107 - val_accuracy: 0.6024\n",
      "Epoch 19/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9935 - accuracy: 0.7059\n",
      "Epoch 00019: val_accuracy did not improve from 0.60240\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.9935 - accuracy: 0.7059 - val_loss: 1.5630 - val_accuracy: 0.5905\n",
      "Epoch 20/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9517 - accuracy: 0.7162\n",
      "Epoch 00020: val_accuracy improved from 0.60240 to 0.60600, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 0.9517 - accuracy: 0.7162 - val_loss: 1.4731 - val_accuracy: 0.6060\n",
      "Epoch 21/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.7289\n",
      "Epoch 00021: val_accuracy did not improve from 0.60600\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.9045 - accuracy: 0.7289 - val_loss: 1.6074 - val_accuracy: 0.5894\n",
      "Epoch 22/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8579 - accuracy: 0.7409\n",
      "Epoch 00022: val_accuracy improved from 0.60600 to 0.60670, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.8579 - accuracy: 0.7409 - val_loss: 1.5225 - val_accuracy: 0.6067\n",
      "Epoch 23/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8202 - accuracy: 0.7507\n",
      "Epoch 00023: val_accuracy improved from 0.60670 to 0.61560, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.8202 - accuracy: 0.7507 - val_loss: 1.5225 - val_accuracy: 0.6156\n",
      "Epoch 24/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7827 - accuracy: 0.7603\n",
      "Epoch 00024: val_accuracy did not improve from 0.61560\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.7827 - accuracy: 0.7603 - val_loss: 1.5289 - val_accuracy: 0.6149\n",
      "Epoch 25/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7435 - accuracy: 0.7725\n",
      "Epoch 00025: val_accuracy improved from 0.61560 to 0.62090, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.7435 - accuracy: 0.7725 - val_loss: 1.4793 - val_accuracy: 0.6209\n",
      "Epoch 26/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7103 - accuracy: 0.7796\n",
      "Epoch 00026: val_accuracy did not improve from 0.62090\n",
      "391/391 [==============================] - 52s 134ms/step - loss: 0.7103 - accuracy: 0.7796 - val_loss: 1.5289 - val_accuracy: 0.6146\n",
      "Epoch 27/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.7870\n",
      "Epoch 00027: val_accuracy did not improve from 0.62090\n",
      "391/391 [==============================] - 51s 132ms/step - loss: 0.6926 - accuracy: 0.7870 - val_loss: 1.5234 - val_accuracy: 0.6188\n",
      "Epoch 28/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.7950\n",
      "Epoch 00028: val_accuracy did not improve from 0.62090\n",
      "391/391 [==============================] - 52s 133ms/step - loss: 0.6603 - accuracy: 0.7950 - val_loss: 1.5542 - val_accuracy: 0.6187\n",
      "Epoch 29/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.8034\n",
      "Epoch 00029: val_accuracy did not improve from 0.62090\n",
      "391/391 [==============================] - 51s 132ms/step - loss: 0.6331 - accuracy: 0.8034 - val_loss: 1.5687 - val_accuracy: 0.6198\n",
      "Epoch 30/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.6009 - accuracy: 0.8125\n",
      "Epoch 00030: val_accuracy improved from 0.62090 to 0.63700, saving model to ResNet_BatchNorm_SGD.hdf5\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.6009 - accuracy: 0.8125 - val_loss: 1.4778 - val_accuracy: 0.6370\n",
      "Epoch 31/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.8209\n",
      "Epoch 00031: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 52s 132ms/step - loss: 0.5744 - accuracy: 0.8209 - val_loss: 1.5842 - val_accuracy: 0.6171\n",
      "Epoch 32/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.8263\n",
      "Epoch 00032: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.5513 - accuracy: 0.8263 - val_loss: 1.5985 - val_accuracy: 0.6205\n",
      "Epoch 33/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8328\n",
      "Epoch 00033: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.5257 - accuracy: 0.8328 - val_loss: 1.5965 - val_accuracy: 0.6235\n",
      "Epoch 34/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.5053 - accuracy: 0.8395\n",
      "Epoch 00034: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.5053 - accuracy: 0.8395 - val_loss: 1.5527 - val_accuracy: 0.6310\n",
      "Epoch 35/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.8435\n",
      "Epoch 00035: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 129ms/step - loss: 0.4881 - accuracy: 0.8435 - val_loss: 1.6201 - val_accuracy: 0.6223\n",
      "Epoch 36/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.8503\n",
      "Epoch 00036: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 131ms/step - loss: 0.4721 - accuracy: 0.8503 - val_loss: 1.6451 - val_accuracy: 0.6246\n",
      "Epoch 37/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.8579\n",
      "Epoch 00037: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.4464 - accuracy: 0.8579 - val_loss: 1.6391 - val_accuracy: 0.6266\n",
      "Epoch 38/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.8618\n",
      "Epoch 00038: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.4348 - accuracy: 0.8618 - val_loss: 1.6302 - val_accuracy: 0.6269\n",
      "Epoch 39/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.8672\n",
      "Epoch 00039: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.4163 - accuracy: 0.8672 - val_loss: 1.6357 - val_accuracy: 0.6253\n",
      "Epoch 40/70\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8713Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.63700\n",
      "391/391 [==============================] - 51s 132ms/step - loss: 0.3992 - accuracy: 0.8713 - val_loss: 1.6201 - val_accuracy: 0.6339\n",
      "Epoch 00040: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net() \n",
    "model.summary()\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_data=ImageDataGenerator(\n",
    "        rotation_range=20,     #randomly rotate images in the range (20 degrees)\n",
    "        horizontal_flip=True,  #randomly flip images\n",
    "        width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
    "        shear_range = 0.2,     #Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "        height_shift_range=0.1,#randomly shift images vertically (fraction of total height)\n",
    "        zoom_range=0.2,        #Range for random zoom\n",
    "        brightness_range = (0.5, 1.5))   #Range for picking a brightness shift value\n",
    "aug_data.fit(x_train)\n",
    "\n",
    "\n",
    "# save model after each epoch\n",
    "checkpoint = ModelCheckpoint(\"ResNet_BatchNorm_SGD.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128), batch_size=128, epochs=70, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "4LG-yhpw39E_",
    "outputId": "bc4ac194-195e-49b3-e35c-583f16bcf15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6489371293705747\n",
      "Recall: 0.637\n",
      "Accuracy: 0.637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "6LNGZeS48xPx",
    "outputId": "4daf332c-baa5-4baa-89eb-6e1764075f79"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xUVfr48c+ZmfRGGjVIqNKSQEKVXhRxEaQJKGAsKPhd0LWs9YcsihVXRXdVFDsSiiuioCggTURKpBelhE5IIb1MO78/ZggBQzKEhEnI83695jUzt5z7TMTz3HvOvecorTVCCCFqLoO7AxBCCOFekgiEEKKGk0QghBA1nCQCIYSo4SQRCCFEDSeJQAghajhJBKJGUUp9opR6wcVtk5RS/Ss7JiHcTRKBEELUcJIIhKiGlFImd8cgrh2SCESV42ySeVwptUMplauUmqOUqqOU+l4pla2UWqGUCi62/WCl1G6lVIZSarVSqlWxde2VUonO/eYD3hcda5BSaptz3w1KqWgXY/ybUup3pVSWUuqYUmraReu7O8vLcK6Pdy73UUq9rpQ6opTKVEqtdy7rrZQ6XsLfob/z8zSl1CKl1BdKqSwgXinVSSn1q/MYp5RS7yilPIvt30Yp9ZNSKl0playUelopVVcplaeUCi22XaxSKkUp5eHKbxfXHkkEoqoaDtwItABuBb4HngbCcfy7nQKglGoBzAMedq5bBnyrlPJ0VoqLgc+BEGChs1yc+7YHPgIeAEKB94ElSikvF+LLBcYDtYC/AZOUUrc5y23kjPdtZ0ztgG3O/WYCccANzpj+Cdhd/JsMARY5jzkXsAH/AMKArkA/4EFnDAHACuAHoD7QDFiptT4NrAZuL1buOCBBa21xMQ5xjZFEIKqqt7XWyVrrE8A64Det9e9a6wLga6C9c7tRwFKt9U/Oimwm4IOjou0CeABvaq0tWutFwOZix7gfeF9r/ZvW2qa1/hQodO5XKq31aq31Tq21XWu9A0cy6uVcfQewQms9z3ncNK31NqWUAbgHeEhrfcJ5zA1a60IX/ya/aq0XO4+Zr7XeqrXeqLW2aq2TcCSyczEMAk5rrV/XWhdorbO11r85130KjAVQShmBMTiSpaihJBGIqiq52Of8Er77Oz/XB46cW6G1tgPHgAbOdSf0hSMrHin2uRHwqLNpJUMplQE0dO5XKqVUZ6XUz84mlUxgIo4zc5xlHCxhtzAcTVMlrXPFsYtiaKGU+k4pddrZXPSiCzEAfAO0Vko1xnHVlam13lTOmMQ1QBKBqO5O4qjQAVBKKRyV4AngFNDAueyc64p9PgbM0FrXKvby1VrPc+G4XwJLgIZa6yDgPeDccY4BTUvYJxUouMS6XMC32O8w4mhWKu7ioYLfBfYBzbXWgTiazorH0KSkwJ1XVQtwXBWMQ64GajxJBKK6WwD8TSnVz9nZ+SiO5p0NwK+AFZiilPJQSg0DOhXb9wNgovPsXiml/JydwAEuHDcASNdaFyilOuFoDjpnLtBfKXW7UsqklApVSrVzXq18BPxbKVVfKWVUSnV19kn8AXg7j+8BPAuU1VcRAGQBOUqplsCkYuu+A+oppR5WSnkppQKUUp2Lrf8MiAcGI4mgxpNEIKo1rfV+HGe2b+M4474VuFVrbdZam4FhOCq8dBz9Cf8rtu8WYALwDnAWOODc1hUPAtOVUtnAVBwJ6Vy5R4FbcCSldBwdxTHO1Y8BO3H0VaQDrwAGrXWms8wPcVzN5AIX3EVUgsdwJKBsHEltfrEYsnE0+9wKnAb+BPoUW/8Ljk7qRK118eYyUQMpmZhGiJpJKbUK+FJr/aG7YxHuJYlAiBpIKdUR+AlHH0e2u+MR7iVNQ0LUMEqpT3E8Y/CwJAEBckUghBA1nlwRCCFEDVftBq4KCwvTkZGR7g5DCCGqla1bt6ZqrS9+NgWohokgMjKSLVu2uDsMIYSoVpRSl7xNWJqGhBCihpNEIIQQNZwkAiGEqOGqXR+BEOI8i8XC8ePHKSgocHcooorw9vYmIiICDw/X5xmSRCBENXb8+HECAgKIjIzkwkFWRU2ktSYtLY3jx4/TuHFjl/eTpiEhqrGCggJCQ0MlCQgAlFKEhoZe9hWiJAIhqjlJAqK48vx7qDGJ4M+zf/L6ltfJs+S5OxQhhKhSakwiOJlzkk92f8KetD3uDkWIa87ixYtRSrFv3z53hyLKocYkgqjwKAB2pO5wcyRCXHvmzZtH9+7dmTfPlVk+y8dms1Va2TVdjUkEId4hNAxoyI4USQRCVKScnBzWr1/PnDlzSEhIAByV9mOPPUbbtm2Jjo7m7bffBmDz5s3ccMMNxMTE0KlTJ7Kzs/nkk0/4+9//XlTeoEGDWL16NQD+/v48+uijxMTE8OuvvzJ9+nQ6duxI27Ztuf/++zk3evKBAwfo378/MTExxMbGcvDgQcaPH8/ixYuLyr3zzjv55ptvrtJfpXqp9NtHnZNwbwFOaK0HXbTOC8fcqXFAGjBKa51UWbFEh0fz26nf0FpLB5u45vzr293sOZlVoWW2rh/Ic7e2KXWbb775hptvvpkWLVoQGhrK1q1b2bRpE0lJSWzbtg2TyUR6ejpms5lRo0Yxf/58OnbsSFZWFj4+PqWWnZubS+fOnXn99dcd8bRuzdSpUwEYN24c3333Hbfeeit33nknTz75JEOHDqWgoAC73c69997LG2+8wW233UZmZiYbNmzg008/rZg/zDXmalwRPATsvcS6e4GzWutmwBs45m+tNNFh0aTmp3I693RlHkaIGmXevHmMHj0agNGjRzNv3jxWrFjBAw88gMnkONcMCQlh//791KtXj44dOwIQGBhYtP5SjEYjw4cPL/r+888/07lzZ6Kioli1ahW7d+8mOzubEydOMHToUMDxQJWvry+9evXizz//JCUlhXnz5jF8+PAyj1dTVepfRSkVAfwNmAE8UsImQ4Bpzs+LgHeUUkpX0mw5MeGO+cO3p26nnn+9yjiEEG5T1pl7ZUhPT2fVqlXs3LkTpRQ2mw2lVFFl7wqTyYTdbi/6XvweeG9vb4xGY9HyBx98kC1bttCwYUOmTZtW5v3y48eP54svviAhIYGPP/74Mn9dzVHZVwRvAv8E7JdY3wA4BqC1tgKZQOjFGyml7ldKbVFKbUlJSSl3MC2CW+Bl9JJ+AiEqyKJFixg3bhxHjhwhKSmJY8eO0bhxY2JiYnj//fexWq2AI2Fcf/31nDp1is2bNwOQnZ2N1WolMjKSbdu2YbfbOXbsGJs2bSrxWOcq/bCwMHJycli0aBEAAQEBREREFPUHFBYWkpfnuE08Pj6eN998E3A0K4mSVVoiUEoNAs5orbdeaVla69la6w5a6w7h4SXOq+ASD6MHrUNbSyIQooLMmzevqEnmnOHDh3Pq1Cmuu+46oqOjiYmJ4csvv8TT05P58+czefJkYmJiuPHGGykoKKBbt240btyY1q1bM2XKFGJjY0s8Vq1atZgwYQJt27ZlwIABF1x1fP7558yaNYvo6GhuuOEGTp92NP/WqVOHVq1acffdd1feH+EaUGlzFiulXgLGAVbAGwgE/qe1Hltsm+XANK31r0opE3AaCC+taahDhw76Siammbl5JvP2zWPjHRvxMLo+KJMQVdHevXtp1aqVu8OosvLy8oiKiiIxMZGgoCB3h3PVlPTvQim1VWvdoaTtK+2KQGv9lNY6QmsdCYwGVhVPAk5LgLucn0c4t6mczOQUHR6N2W5m/9n9lXkYIYSbrVixglatWjF58uQalQTK46p3oSulpgNbtNZLgDnA50qpA0A6joRRqaLDowHYnrKdtmFtK/twQgg36d+/P0eOXHJ2RlHMVUkEWuvVwGrn56nFlhcAI69GDOfU9atLbd/a7EjZwZ2t7ryahxZCiCqpxjxZXFxMeIx0GAshhFONTATRYdEczzlOWn6au0MRQgi3q5mJwNlPsDN1p5sjEUII96uRiaBVaCuMyijNQ0JcoT59+rB8+fILlr355ptMmjTpkvv07t2bc7eA33LLLWRkZPxlm2nTpjFz5sxSj7148WL27Dk/rPzUqVNZsWLF5YRfqocffpgGDRpc8NTztapGJgIfkw8tgltIIhDiCo0ZM6ZoxNFzEhISGDNmjEv7L1u2jFq1apXr2BcngunTp9O/f/9ylXUxu93O119/TcOGDVmzZk2FlFmSc09eu1uNTATgaB7amboTm13GOBeivEaMGMHSpUsxm80AJCUlcfLkSXr06MGkSZPo0KEDbdq04bnnnitx/8jISFJTUwGYMWMGLVq0oHv37uzff/45nw8++ICOHTsSExPD8OHDycvLY8OGDSxZsoTHH3+cdu3acfDgQeLj44uGnVi5ciXt27cnKiqKe+65h8LCwqLjPffcc8TGxhIVFXXJiXRWr15NmzZtmDRp0gVzLCQnJzN06FBiYmKIiYlhw4YNAHz22WdFT1GPGzcO4IJ4wDGk9rmye/ToweDBg4uGvbjtttuIi4ujTZs2zJ49u2ifH374gdjYWGJiYujXrx92u53mzZtzbqgdu91Os2bNuJKhd8ANzxFUFTHhMczfP5+DmQdpEdzC3eEIceW+fxJOV3C/V90oGPjyJVeHhITQqVMnvv/+e4YMGUJCQgK33347SilmzJhBSEgINpuNfv36sWPHDqKjo0ssZ+vWrSQkJLBt2zasViuxsbHExcUBMGzYMCZMmADAs88+y5w5c5g8eTKDBw9m0KBBjBgx4oKyCgoKiI+PZ+XKlbRo0YLx48fz7rvv8vDDDwOOsYoSExP573//y8yZM/nwww//Es+8efMYM2YMQ4YM4emnn8ZiseDh4cGUKVPo1asXX3/9NTabjZycHHbv3s0LL7zAhg0bCAsLIz09vcw/a2JiIrt27aJx48YAfPTRR4SEhJCfn0/Hjh0ZPnw4drudCRMmsHbtWho3bkx6ejoGg4GxY8cyd+5cHn74YVasWEFMTAxXMvQO1PArAkCah4S4QsWbh4o3Cy1YsIDY2Fjat2/P7t27L2jGudi6desYOnQovr6+BAYGMnjw4KJ1u3btokePHkRFRTF37lx2795dajz79++ncePGtGjhOMG76667WLt2bdH6YcOGARAXF0dSUtJf9jebzSxbtozbbruNwMBAOnfuXNQPsmrVqqL+D6PRSFBQEKtWrWLkyJGEhYUBjuRYlk6dOhUlAYBZs2YRExNDly5dOHbsGH/++ScbN26kZ8+eRdudK/eee+7hs88+AxwJpCLGUaqxVwTXBVxHkFcQO1J2MKLFiLJ3EKKqK+XMvTINGTKEf/zjHyQmJpKXl0dcXByHDx9m5syZbN68meDgYOLj48scMvpS4uPjWbx4MTExMXzyySdFs5eVl5eXF+CoyEtqo1++fDkZGRlERTmmt83Ly8PHx4dBgwb9ZdvSFB9e2263FzWfAfj5+RV9Xr16NStWrODXX3/F19eX3r17l/q3atiwIXXq1GHVqlVs2rSJuXPnXlZcJamxVwRKKaLDouWKQIgr5O/vT58+fbjnnnuKrgaysrLw8/MjKCiI5ORkvv/++1LL6NmzJ4sXLyY/P5/s7Gy+/fbbonXZ2dnUq1cPi8VyQaUXEBBAdnb2X8q6/vrrSUpK4sCBA4BjZNJevXq5/HvmzZvHhx9+SFJSEklJSRw+fJiffvqJvLw8+vXrx7vvvgs4puPMzMykb9++LFy4kLQ0x3NJ55qGIiMj2brVMfjykiVLsFgsJR4vMzOT4OBgfH192bdvHxs3bgSgS5curF27lsOHD19QLsB9993H2LFjGTlyZNF8DVeixiSCwoMHSX75FezFsnJ0eDQHMw+SZa7Y6f2EqGnGjBnD9u3bixJBTEwM7du3p2XLltxxxx1069at1P1jY2MZNWoUMTExDBw48IIhpp9//nk6d+5Mt27daNmyZdHy0aNH89prr9G+fXsOHjxYtNzb25uPP/6YkSNHEhUVhcFgYOLEiS79jry8PH744Qf+9re/FS3z8/Oje/fufPvtt7z11lv8/PPPREVFERcXx549e2jTpg3PPPMMvXr1IiYmhkcecczBNWHCBNasWVM033Lxq4Dibr75ZqxWK61ateLJJ5+kS5cuAISHhzN79myGDRtGTEwMo0aNKtpn8ODB5OTkVNzw2lrravWKi4vT5ZG9erXec31Lnb1mTdGyX078ott+0lb/cuKXcpUphLvt2bPH3SEIN9i8ebPu3r37JdeX9O8Cx2CfJdarNeaKwLdrVwx+fmT/9FPRsqiwKBRKmoeEENXGyy+/zPDhw3nppZcqrMwakwgMnp749+pF9spVaJvj2YEAzwCaBDWRRCCEqDaefPJJjhw5Qvfu3SuszBqTCAACbuyPLT2d/MTEomXR4dHsSN2Brtz5cIQQosqqzDmLvZVSm5RS25VSu5VS/yphm3ilVIpSapvzdV9lxQPg16MnytOTrGLNQ9Hh0WQWZnI0+2hlHloIIaqsyrwiKAT6aq1jgHbAzUqpLiVsN19r3c75+usjfhXI6O+HX7duZK9YUXQFIA+WCSFqusqcs1hrrXOcXz2cL7e3vwT074/15CkKdjuecmwa1BRfky/bU7a7OTIhhHCPSu0jUEoZlVLbgDPAT1rr30rYbLhSaodSapFSquElyrlfKbVFKbXlSgdX8u/bB4xGslc4moeMBiNRYVFyRSBEOZwbSE1Ub5WaCLTWNq11OyAC6KSUuni2+G+BSK11NPAT8Oklypmtte6gte5wpYMrmYKD8e3Ykeyfzo9bHh0ezR9n/yDfmn9FZQshRHV0Ve4a0lpnAD8DN1+0PE1rXej8+iEQdzXiCejfH/PBgxQeOgQ4EoFN29iTdulBsYQQl6a15vHHH6dt27ZERUUxf/58AE6dOkXPnj1p164dbdu2Zd26ddhsNuLj44u2feONN9wcvai0QeeUUuGARWudoZTyAW4EXrlom3pa61POr4OBvZUVT3EB/fuR/MILZP+0Aq8H7icqzDG41I6UHcTVuSq5SIgK98qmV9iXXvL4+uXVMqQlT3R6oszt/ve//7Ft2za2b99OamoqHTt2pGfPnnz55ZcMGDCAZ555BpvNRl5eHtu2bePEiRPs2rULoMQZysTVVZlXBPWAn5VSO4DNOPoIvlNKTVdKnRtjdorz1tLtwBQgvhLjKeJRty7e0dFFTxmH+oQS4R8h/QRClNP69esZM2YMRqOROnXq0KtXLzZv3kzHjh35+OOPmTZtGjt37iQgIIAmTZpw6NAhJk+ezA8//EBgYKC7w6/xKu2KQGu9A2hfwvKpxT4/BTxVWTGUJuDG/qS8/m8sJ0/iUb8+0eHRbD69Ga01Sil3hCTEFXHlzP1q69mzJ2vXrmXp0qXEx8fzyCOPMH78eLZv387y5ct57733WLBgAR999JG7Q63RatSTxcUFOOc2zV6xEoDuDbqTkp/C5tOb3RmWENVSjx49mD9/PjabjZSUFNauXUunTp04cuQIderUYcKECdx3330kJiaSmpqK3W5n+PDhvPDCCyQWe9JfuEeNTQRejRvj1bxZUfPQjY1uJNAzkIV/LHRzZEJUP0OHDi2as7dv3768+uqr1K1bl9WrVxcNST1//nweeughTpw4Qe/evWnXrh1jx46t0MHTRPmo6jbGTocOHfSWLVsqpKyUWbNIfe99mq9fhykkhFc2vULC/gRWjlxJiHfZ080J4W579+6lVatW7g5DVDEl/btQSm3VWncoafsae0UAzuYhu52cVasAGNFiBFa7lSUHlrg5MiGEuHpqdCLwatUKjwYNih4ua1qrKbG1Y1n05yIZjVQIUWPU6ESglCLgxhvJ3bABW45jWKQRLUZwJOuIdBoLIWqMGp0IwHEbqbZYyFmzBpBOYyFEzVPjE4FPu3YYw8LIXuFoHvI2eTO46WBWHF1BekG6m6MTQojKV+MTgTIaCejXj9w1a7EXOoY9kk5jIURNUuMTATjuHrLn5ZG7YQMgncZCuKpPnz4sX778gmVvvvkmkyZNuuQ+vXv35twt4LfcckuJYw1NmzaNmTNnlnrsxYsXs2fP+YEip06dyooVK0rZwzWrV69m0KBBV1xOdSKJAPDr3AlDQMAFQ1NLp7EQZRszZgwJCQkXLEtISGDMmDEu7b9s2TJq1apVrmNfnAimT59Of+eIAeLySCIAlKcn/r17k7NyJdpsBqTTWAhXjBgxgqVLl2J2/n+TlJTEyZMn6dGjB5MmTaJDhw60adOG5557rsT9IyMjSU1NBWDGjBm0aNGC7t27s3///qJtPvjgAzp27EhMTAzDhw8nLy+PDRs2sGTJEh5//HHatWvHwYMHiY+PZ9GiRQCsXLmS9u3bExUVxT333EOhs9k3MjKS5557jtjYWKKioti3z/XRWufNm0dUVBRt27bliScc4zpdakjtWbNm0bp1a6Kjoxk9evRl/lWvvkobdK66Cbp1EFnffkv2qp8JvHlAUadxwv4E0gvS5UljUeWdfvFFCvdW7DDUXq1aUvfppy+5PiQkhE6dOvH9998zZMgQEhISuP3221FKMWPGDEJCQrDZbPTr148dO3YQHR1dYjlbt24lISGBbdu2YbVaiY2NJS7OMST8sGHDmDBhAgDPPvssc+bMYfLkyQwePJhBgwYxYsSIC8oqKCggPj6elStX0qJFC8aPH8+7777Lww8/DEBYWBiJiYn897//ZebMmXz4YdlTpZ88eZInnniCrVu3EhwczE033cTixYtp2LBhiUNqv/zyyxw+fBgvL69qMcy2XBE4+XXrhqluXTK++qpomXQaC1G24s1DxZuFFixYQGxsLO3bt2f37t0XNONcbN26dQwdOhRfX18CAwMZPHhw0bpdu3bRo0cPoqKimDt3Lrt37y41nv3799O4cWNatGgBwF133cXatWuL1g8bNgyAuLg4kpKSXPqNmzdvpnfv3oSHh2MymbjzzjtZu3btJYfUjo6O5s477+SLL77AZKr659tVP8KrRBmN1Bo2jNR33y0amrp4p/Fdbe6S4alFlVbamXtlGjJkCP/4xz9ITEwkLy+PuLg4Dh8+zMyZM9m8eTPBwcHEx8dTUFBQrvLj4+NZvHgxMTExfPLJJ6xevfqK4vXy8gLAaDRitVqvqKzg4OASh9ReunQpa9eu5dtvv2XGjBns3LmzSicEuSIoJsh5ppDx9ddFy6TTWIjS+fv706dPH+65556iq4GsrCz8/PwICgoiOTmZ77//vtQyevbsyeLFi8nPzyc7O5tvv/22aF12djb16tXDYrEwd+7couUBAQFkZ2f/pazrr7+epKQkDhw4AMDnn39Or169rug3durUiTVr1pCamorNZmPevHn06tWrxCG17XY7x44do0+fPrzyyitkZmaS4xy5oKqqtESglPJWSm1SSm13zkL2rxK28VJKzVdKHVBK/aaUiqyseFzhGdEAv65dyfjqK7TNBkinsRCuGDNmDNu3by9KBOeGnm7ZsiV33HEH3bp1K3X/2NhYRo0aRUxMDAMHDqRjx45F655//nk6d+5Mt27daNmyZdHy0aNH89prr9G+fXsOHjxYtNzb25uPP/6YkSNHEhUVhcFgYOLEiZf1e1auXElERETRKykpiZdffpk+ffoQExNDXFwcQ4YMKXFIbZvNxtixY4mKiqJ9+/ZMmTKl3HdGXS2VNgy1crSj+Gmtc5RSHsB64CGt9cZi2zwIRGutJyqlRgNDtdajSiu3IoehLknWsmWceORRGn74If7dHf94ZXhqUVXJMNSiJFVmGGrtcO56yMP5ujjrDAE+dX5eBPRTbm6I9+/fH2NQEBlfLSpaJp3GQohrWaX2ESiljEqpbcAZHJPX/3bRJg2AYwBaayuQCYSWUM79SqktSqktKSkplRkyBk9Pgm4bQvaKlVjPngXOP2mcsD8Bm91WqccXQoirrVITgdbaprVuB0QAnZRSbctZzmytdQetdYfw8PCKDbIEQcOHg8VC1pLzVwDjWo/jRM4JVhy98kfYhahIMgyKKK48/x6uyl1DWusM4Gfg5otWnQAaAiilTEAQkHY1YiqNd4sWeMdEk7Ho/FhDfRr2oVFgIz7e9bH8jyeqDG9vb9LS0uTfpAAcSSAtLQ1vb+/L2q/SbmxVSoUDFq11hlLKB7gReOWizZYAdwG/AiOAVbqK/IuuNXw4p6c+R8H27Y6hqg1Gxrcez/Mbn2dL8hY61u1YdiFCVLKIiAiOHz9OZTeZiurD29ubiIiIy9qnMp9wqAd8qpQy4rjyWKC1/k4pNR3YorVeAswBPldKHQDSgSozKEfgLX8j+eVXyPjqK3zatQNgcNPB/Gfbf/h418eSCESV4OHhQePGjd0dhqjmKvOuoR1a6/Za62itdVut9XTn8qnOJIDWukBrPVJr3Uxr3Ulrfaiy4rlcRn8/AgfeTNbSZdhzcwHHpDVjWo5h3Yl1HDh7wM0RCiFExZAni0tRa/gI7Hl5ZP3wQ9Gy0dePxsfkwye7P3FfYEIIUYEkEZTCp307PJs2JWPh+WcKannXYmizoSw9vJTk3GQ3RieEEBVDEkEplFLUGj6c/G3bKDxwviloXOtx2LWduXvnlrK3EEJUD5IIyhA0ZDB4eJCx6Pzw1BEBEdzU6CYW/rGQHHPVHkxKCCHKIomgDKbQUAL69CHzm2+KZi8DiG8bT44lh0V/LCplbyGEqPokEbig1sgR2M6eJXvVz0XL2oS2oXPdzny+93MsNosboxNCiCsjicAFfjfcgKlePc7OnXvBE5zxbeM5k3eGZYeXuTE6IYS4MpIIXKCMRkLvvZe8zZvJ/vGnouXd6nejeXBzPtn9iTziL4SotiQRuCh49Ci8rr+e5Jdfxp6fDzjuKopvE8+BjAOsP7HezREKIUT5SCJwkTKZqDv1/2E9dYrU2bOLlg+MHEht39p8vPtjN0YnhBDlJ4ngMvjGxRE4+FbSP5yD+cgRADyMHoxvPZ7NpzezO3W3myMUQojLJ4ngMtV+7DGUpyfJL75UtGx48+EEeATwn23/cWNkQghRPpIILpNH7dqE/f3v5KxZU3Q7qb+nPw/EPMC6E+tYe3ytmyMUQojLI4mgHELG3oln06Ykv/gi9sJCAO5oeQeRgSonGwgAACAASURBVJG8uvlVea5ACFGtSCIoB+XhQd1nn8Fy/Dhpc+YAjr6Cf3b8J0eyjvDF3i/cHKEQQriu0hKBUqqhUupnpdQepdRupdRDJWzTWymVqZTa5nxNrax4Kppf164E3Hwzae/Pxnz8BAA9InrQK6IX7+94n9T8VDdHKIQQrqnMKwIr8KjWujXQBfg/pVTrErZbp7Vu53xNr8R4KlydJ/4JBgNnXnm5aNnjHR+n0FbIm1vfdGNkQgjhusqcoeyU1jrR+Tkb2As0qKzjuYNHvXqETZxI9k8ryFnneKCsUWAjxrcezzcHv2FHyg43RyiEEGUrMxEopW5VSl1RwlBKRQLtgd9KWN1VKbVdKfW9UqrNlRzHHULujsezUSOSX3gBu3N00vuj7yfcJ5yXN72MXdvdHKEQQpTOlQp+FPCnUupVpVTLyz2AUsof+Ap4WGudddHqRKCR1joGeBtYfIky7ldKbVFKbUlJSbncECqVwdOTOs8+g/nIEdI/+ggAPw8/Ho57mJ2pO1lycImbIxRCiNKVmQi01mNxnM0fBD5RSv3qrJgDytpXKeWBIwnM1Vr/r4Sys7TWOc7PywAPpVRYCdvN1lp30Fp3CA8PL/tXXWX+PXoQMGAAKf/5LwX79wMwqMkgosOjeXPrmzJ5jRCiSnOpycd5Jr8ISADqAUOBRKXU5Evto5RSwBxgr9b635fYpq5zO5RSnZzxpF3WL6gi6j43FWNQECf/+QR2sxmDMvBUp6dIK0hj9o7ZZRcghBBu4kofwWCl1NfAasAD6KS1HgjEAI+Wsms3YBzQt9jtobcopSYqpSY6txkB7FJKbQdmAaN1NR3P2RQSQr3p0yncv5/UdxxDTbQNa8vQZkP5fO/nJGUmuTdAIYS4BFVWvauU+hSYo7X+y9gJSql+WuuVlRVcSTp06KC3bNlyNQ95WU4+8wyZXy+m0dwv8G3fntT8VG79+lba127Pf/v/193hCSFqKKXUVq11h5LWudI0NA3YVKwwH+ddQFztJFAd1HnqKTzq1uXUk09hz8sjzCeMiTETWXdiHSuOrHB3eEII8ReuJIKFQPF7IG3OZaIERn9/6r30EuYjRzgz83XAMQ5Rq5BWTN0wlRM5J9wcoRBCXMiVRGDSWpvPfXF+9qy8kKo/v86dCLlrPGe//JKcX37Bw+jB671fBw2PrX4Ms81cdiFCCHGVuJIIUpRSg899UUoNAWQgnTKE/+MfeDZpwqmnn8GWlUXDgIY83+15dqXt4vUtr7s7PCGEKOJKIpgIPK2UOqqUOgY8ATxQuWFVfwZvb+q/8jLW1FSSZ8wAoF+jfoxtNZYv933Jj0k/ujlCIYRwcOWBsoNa6y5Aa6CV1voGrfWByg+t+vOJiiLsgQfI/GYJWT86Kv5H4h4hOiyaqRumcjTrqJsjFEIIFx8oU0r9DXgQeEQpNbU6DRftbmGTJuLdujWnn5uG5fRpPIwezOw1E5PBxKNrHqXQVujuEIUQNZwrD5S9h2O8ocmAAkYCjSo5rmuG8vCg/quvYC8s5PDwEeRu2EA9/3q82P1F9qXv45VNr7g7RCFEDefKFcENWuvxwFmt9b+ArkCLyg3r2uLVrBmNF8zHGFyLo/fex5m33qJH3Ru4p+09LPxjId8d+s7dIQohajBXEkGB8z1PKVUfsOAYb0hcBq9mzWi8cCFBw4aS9u57HI2/m0n1bye2dizTf53OoYxD7g5RCFFDuZIIvlVK1QJewzFsdBLwZWUGda0y+PhQf8YM6r/yMvl79nB02EheMA3Hx+TDo2seJdeS6+4QhRA1UKmJwDkhzUqtdYbW+iscfQMttdbSWXwFgoYMofGihZjCw8mZ/ARv7uvAkbOHmLJqinQeCyGuulITgdbaDvyn2PdCrXVmpUdVA3g1aULkgvnUGjkS73nL+HBJfY7v3sRjqx/DYre4OzwhRA3iStPQSqXU8HPzBoiKY/D2pt7z06k/cyZ+x9L490ea8Hkrmfrzk9jsNneHJ4SoIVxJBA/gGGSuUCmVpZTKVkpdPOWkuAJBg/5G02VLqXXzQEau19z47DI++OjvVNOpGYQQ1YwrTxYHaK0NWmtPrXWg83vg1QiuJjGFh9Ng5mtc99EcAr2C6DVzNavuuRXLmTPuDk0IcY1z5YGyniW9XNivoVLqZ6XUHqXUbqXUQyVso5RSs5RSB5RSO5RSseX9IdcKvxtuoP0Pq9lzWzThmw6yb8CNpM+di7ZJU5EQonK4MkPZt8W+egOdgK1a675l7FcPqKe1TnROdL8VuE1rvafYNrfgeGL5FqAz8JbWunNp5Vb1Gcoqil3beWXRQzSZs5LoJI1Pu3Y0fO9djLVquTs0IUQ1dEUzlGmtby32uhFoC5x1Yb9TWutE5+dsYC/Q4KLNhgCfaYeNQC1nAqnxDMrA48PfYMPj/Xn7VgO5u3Zy9J57sWXKTVtCiIrl0qBzFzkOtLqcHZxTW7YHfrtoVQPg2EVlX5wsUErdr5TaopTakpKSclnBVmcmg4lXe7+G5cYbeHWYIv+P/Ry9bwK27Gx3hyaEuIa40kfwtrMdf5ZS6h1gHY4njF2ilPIHvgIe1lqX624jrfVsrXUHrXWH8PDw8hRRbXkZvZjVdxae3bvw6m2avL17OHbfBGw5Oe4OTQhxjXDlimALjvb9rcCvwBNa67GuFK6U8sCRBOZqrf9XwiYngIbFvkc4l4lifEw+vNPvHfz69Ob1wZq8nTs4dv8D2HNlSAohxJVzJREsAr7QWn+qtZ4LbFRK+Za1k/MBtDnAXq31vy+x2RJgvPPuoS5Aptb6lKvB1yReRi/e7P0mtW4awBuDFXnbfufYAxOx5+W5OzQhRDXn0pPFgE+x7z7AChf26waMA/oqpbY5X7copSYqpSY6t1kGHAIOAB/gmPxGXIKH0YNXe75KyC2DeOtWRe7WrRyb9CD2/Hx3hyaEqMZMLmzjrbUuapDWWue4ckWgtV6PYyKb0rbRwP+5EINwMhlMvNj9RaabvHnHvoi/f/cbxx78Pxq++1+w2bCcOYP1TArWM8lYz5xxvFJS8ekQR/CoUSij0d0/QQhRxbiSCHKVUrHnbgVVSsUBcgrqRkaDkee6PsdLBk/+a/+SB5f9yh+dOqPN5r9sa/D1xRAURNayZWR+9T/qTpuGT1RbN0QthKiqXEkEDwMLlVIncZzh18UxdaVwI4My8HTnp/m3yZvXvD/i1oyGdIsZhHfd+phq18ZUuw6m2rUx+vuhtSb7hx84/eKLJN1+O8F33EH4ww9hDAhw988QQlQBZT5ZDEV3/1zv/Lpfa+22cZJrypPFrtJa8/6O9/nPtv/QOrQ1/+79bxr4/+VRDABs2dmkvPkWZ7/8EmNYKHWfeoqAgQORgWWFuPZd0ZPFSqn/A/y01ru01rsAf6WUdOpWEUopJsZMZFafWRzNOsqo70ax4cSGErc1BgRQ9/89S+SCBXiE1+bEI49ybML9mI8evcpRCyGqElfuGpqgtc4490VrfRaYUHkhifLoc10fEgYlEO4TzsQVE5m9YzZ2bS9xW5+otkQuXECdZ54h//ffOTToVpJffkVGOhWihnIlERiLT0qjlDICnpUXkiivRoGNmHvLXAY2Hsjbv7/NQz8/RJa55Ie5ldFIyLixNFm2jMCBN5P+2Wcc7H8jp59/AcspeZRDiJrEldFHX8MxV/H7zkUPAEe11o9Vcmwlkj6Csmmt+XLfl8zcPJP6/vV5o88btAhuUeo+5iNHSP3gAzIXfwNKUWvoUELvn4BnRMRViloIUZlK6yNwJREYgPuBfs5FO4C6Wmu33P8vicB1icmJPLrmUXItuTzd+WmGNB1SZsew5cQJUj/8kMxFX6HtdoIGDyb0nrsx1a0LyoAyGsBoRBmc79LRLES1cEWJwFlAe+AO4HYcTwJ/pbV+p0KjdJEkgsuTkpfCP9f+ky3JW+jbsC9Tu04l1Ce0zP0syWdI/2gOZ+cvQBcUXHpDpTCGhRJy550E33EHxkCZvE6IqqhciUAp1QIY43ylAvOBx7TWjSorUFdIIrh8NruNL/Z+wazEWfh5+DG161T6N+rv0r7W1FSyV6zAXlAANjvabgObHbQdbbOD3Ub+rl3krl2Hwc+P4DGjCR4/Ho/atSv5VwkhLkd5E4Edx5DT92qtDziXHdJaN6m0SF0giaD8Dpw9wNPrn2Zv+l5ubXIrT3Z+kkDPijmDL9i3j7TZH5D1ww8ok4mgoUMJve9ePBs2LHtnIaoBW0YG5mPHwGDA4OODwdsb5e1d9K4M5Zne5eopbyK4DRiNY/C4H4AE4EOtdePKCtQVkgiujMVuYfaO2Xyw4wPCfMKY3m06N9S/ocLKNx85Qtqcj8j8+mu0zUbgwIGE3ncv3q0uay6jK2LLyCBn3TqyV63CnplFnWefwauJW89fRDWh7XYsJ09hPnSQwkOHMB86TOGhg5gPHcaWnl7qvsrLC4O3NwZ/f8crwB+jnz+GgAAM/n4YAwJQHh7YCwrRBQXYzYXogkJ0YUHRMuXlhSk8/MJX7fOfDd7e5f5tV9pZ7IdjSskxQF/gM+BrrfWP5Y7oCkgiqBi7Unfx9PqnOZx5mFHXj+KRuEfw9ShzLEGXWZLPkP7pp2QkJGDPy8OnXTuCx4wm4OabMXh5VdhxzjEnJZH982pyVq0iLzERbDaMYWFgtaItFuq/+goB/fqVXVAF0WYzOet/wa9LZwy+Ffd3FZXDcuIEZxMSyFj0Fbaz52fiNQYF4dm0KZ5NGuPVpCmeja4DwJ5f4KjA8wvQBfnOijwfe14+9twcbDm52LOzsefkYMvJwZ6Tgz07G22xOK4evLwweHk5rii8vFBeXihvL3R+AdaUFKxpaWCz/SXO0PvupfZj5bth84o7i4sVFAyMBEZpra/e/1XFSCKoOAXWAmb9Posv9nxBXb+6PNvlWXpG9KzQY9gyM8n4+msyEuZjTkrCWKsWQcOGETx6FJ7XXVfucu2FheQnJpKzfj05P6/GfOgQAF4tWuDfpw8BffvgHRWFNTmZ45OnULBrF2EPPkjY3/+v0i/hbRkZHJ/yEHmbNmEMCyPswUkEjxyJ8vCo1ONeC7TWFOzajeXECaxpqdjS0rCmpmFNS8OWmup4z8py3K1mNILRgDIYHaPqOu9mM4aG4te1K37du+ETFYUylTykmtaavN9+I/2LL8hZ9TMAAf364tejB15NmuDZpAmmkJAK/32u3GmnbTZsGRmOpJCS4hhROCUFn+go/G4o3xV8hSWCqkASQcVLTE5k+q/TOZh5kBsb3ciTnZ6ktm/FdvZqrcnbuJGz8xLIXrkSbDb8unUjeMxo/Lp2xeDnV/r+NhsFe/eR++sG8n79lbytiejCQjCZ8OvUEf/effDv26fE5x7shYWcnvYvMr/+Gv/evan/2qsuDbhnTUtzjN7q41PmtucUHj7M8YmTsJw8SdjkyeSsXUP+lq14XHcd4Q9NIXDgwCrflnw5tN2OLTOzqJK2pqRiS0/Dq2Ur/Dp3uqyyLGfOcHrav8hZter8QqUwBgdjCg3FGBaKKTQMY1AQaI222cBuc9y0YLOh7Y538/HjFOzcCVpjCAzEr0sX/Lp3w79bNzwaNMCem0vmkiWkz52L+cBBjLVqUWvkSILHjMajfv0K/gtVHW5JBEqpj4BBwBmt9V/GPVZK9Qa+AQ47F/1Paz29rHIlEVQOi83CJ7s/4b3t7+Fp9OSh2IcY2WIkRkPFz19gST5DxqKFZCxYiDU5GQDl44MpJARjaKjzPQRTSCiGgAAKdu8mb+NGbJmZAHg1b47fDV3x7doV3w4dMfqXnkTAkYjOfvklyS+9jGdEBBHvvI1Xs2Z/2c58/ATZP/5I9vLl5G/fjjEkhPApU6g1YvglzyzPyd34G8cfeghlNBLxztv4xsaitSZ37VrO/PsNCvfvx6t1K2o/8ih+3W6oVs9gWM+epXDvXgr27KFgz17MSUlYU1OxpqeD1VriPv59+lDniX/iGRlZatlaa7K++47TL8xAFxQQPmUyft26OSr/4OAy/+6Xijdv40Zy1q8n95cNWE+fBsAzMhJrair2nBy8W7cmeOxYAv92S6U0V1Y17koEPYEc4LNSEsFjWutBl1OuJILKdTTrKM9vfJ6NpzYSHRbN1K5TuT7k+rJ3LAdttZKzbh3mgwexpqVjS0/DmpaONT0NW1q6o5KxWDDVreu41L+hK76dO1/Rral5W7Zw/KGH0fn5jn6D/v0xHztG9vLlZC3/0XEmCXi3bo1/v77kbviV/K1b8WrenNpPPoF/t24llpuxaBGnpv0Lz8hGNHzvvb9cmWi7nazvviPlrVlYTpzAt3NnQidMwBh06bu2tMXqbH8uwJ6X7/icX4C9IB+dX4BHw4b49+6FKTjY5d+vbTbyf/+d3E2bAJzt094YvB3vytvR4aktFgr27nW89uzBevL8sCMe9evj2bSpowMzNBRTeJgjgYeFYwoLxVirFplff03qu+9hN5sJufNOwh6cVOIzJtaUFE5N+xc5K1fi064d9V58Ea8mFXs/itYa88GD5P7yCzkbNmAMCiJ4zBh82rWrVsn4SrmtaUgpFQl8J4mgetFas/TwUl7b/BqZhZmMbz2ee6PuJcgr6KrHYc/Nw+DnW6H/w1pOn+b4lIco2LEDz6ZNMR88CIB3VBSBA24iYMCAottetdZk//gTZ157Dcvx4/j36kXtJ/5ZdBeSttk48+9/kz7nI/y6daPBm2+U2uxkN5vJmL+A1HffLfMuFJcYDPjGxRHQvx/+/fqV3DRWUEDuhg1kr1xJzs+rXT+uUnhGRuLdujXerVvh3bo1Xi1bupx4rKmppLz1FhmLvsJYqxbhUyZTa+RIlMnkuApYuozk55/Hnp9P+EMPERJ/l8ygV4mqciL4CjgOnMSRFHaXVaYkgqsnszCTN7a+wVd/foWPyYdhzYcxrvW4S853UJ3YCws5M/N1Cvfuxb9vXwJuugnPiEv/LrvZzNnPP3ec5ebnEzx6NKH33sPpGS+Ss3IlwXeMoc7TT7vcjGHLySX/90RHO/clKKMRg48Pysfn/H3rzs/K05OCvXvJWbmS7BUrKfzjDwC8rr+egH798O/Zg8KkJHJWriRn/S/o/HwMAQH49+pFQP9++HXvgcHby3G3i9l5O2PRrYwFKIMBr2bNyuy7cUXB3r0kv/gSeZs349W8OWGT/07Wt9+S/dMKvGOiqf/SS3J771VQVRNBIGB3zoF8C/CW1rr5Jcq5H8d4R1x33XVxR44cqbSYxV/9cfYPPt39KcsOLUOjuSnyJu5uczetQq/eswFVhTUtjZS33yZjwUKw28FgoM5TTxEybqxb4zIfPUr2ylVkr1xBfuLvjtgAU506BPTrR0D/fvh26IDydM/AwVprsn/6iTOvOq6slKcn4VMmE3L33XIVcJVUyURQwrZJQAetdWpp28kVgfuczj3NF3u+YNGfi8i15NKlXhfubnM3Xet3rVFtrQCFf/5J2kcfE3jLQPx79HB3OBewpqeTt3EjHg2vw7ttmyr138ZeWEjWd9/h0769XAVcZVUyESil6gLJWmutlOoELAIa6TICkkTgflnmLBbuX8jcvXNJyU+hVUgrpsROoVv9blWq0hFCnOeuu4bmAb2BMCAZeA7wANBav6eU+jswCbAC+cAjWuuS51gsRhJB1WG2mVl6aCmzd8zmeM5xOtbtyD9i/0FUeJS7QxNCXEQeKBOVymKzsPCPhby/433SC9K5sdGNTG4/mcZBbh2WSghRjCQCcVXkWnL5bPdnfLL7EwpthQxtPpRJMZMq/CllIcTlk0Qgrqq0/DRm75jNgj8WYFImxrQaw/jW4wnzCXN3aELUWJIIhFscyz7Gf7b9h2WHluFp9GR48+Hc3fZu6vrVdXdoQtQ4kgiEWyVlJjFn1xy+O/gdKBjcdDD3tr2X6wLLP/qoEOLySCIQVcLJnJN8vOtj/vfn/7BqKwMiBzAhagLNg0t8jlAIUYEkEYgqJTU/lc/2fMb8ffPJs+bRqW4nBkQOoN91/Qj1CXV3eEJckyQRiCopszCThH0JLD28lMOZhzEoAx3qdOCmRjfRr1E/6VwWogJJIhBVmtaaAxkHWJ60nB+P/FiUFOLqxHFTo5sY2HjgVR/5VIhrjSQCUW2cSwo/HvmRH5N+5FDmIXxMPgxuOpg7W90pD6kJUU6SCES1tS99H3P3zmXpoaVY7BZ6RvRkbKuxdKnXRcY1EuIySCIQ1V5qfioL9i9g/v75pBek0zy4OeNajeOWJrfgZbz2pxkU4kpJIhDXjEJbIcsOLePzvZ/z59k/CfYKpnfD3vRq2Iuu9bri6+Hr7hCFqJIkEYhrjtaaTac3seiPRaw/sZ4cSw6eBk861utI74je9IroRT3/eu4OU4gqQxKBuKZZ7BYSkxNZc3wNa46t4Wj2UQBaBLegd8Pe3NToJloEt5A+BVGjSSIQNYbWmqSsJNYcW8Oa42tIPJOIXduJDIxkQOQABkQOoFmtZpIURI0jiUDUWOkF6aw4soIfk35kc/Jm7NpOk6AmRUmhaa2m7g5RiKvCXTOUfQQMAs5cYqpKBbwF3ALkAfFa68SyypVEIMorNT+VlUdWsvzIcrac3oJG06xWM26OvJmBjQfKIHjimuauRNATyAE+u0QiuAWYjCMRdAbe0lp3LqtcSQSiIqTmp/Jj0o8sT1pO4hnH+Ueb0DYMbDyQAZEDZKhscc2pqpPXvw+s1lrPc37fD/TWWp8qrUxJBKKinc49zfKk5Xx/+Ht2p+0GILZ2LDc3vpm+DftSx6+OmyMU4spV1UTwHfCy1nq98/tK4Amt9V9qeaXU/cD9ANddd13ckSNHKi1mUbMdzTrKD0k/8P3h7zmQcQCAxkGN6Vy3M13qdaFD3Q4y7pGolqp9IihOrgjE1XLg7AF+OfkLG09tZGvyVvKt+RiUgdYhrelcrzOd63Umrk4cnkZPd4cqRJlKSwSmqx1MMSeAhsW+RziXCVElNAtuRrPgZtzV5i4sNgs7U3fy26nf2HhqI5/u/pQ5u+bgY/Kha72u9GrYix4NehDuG+7usIW4bO5MBEuAvyulEnB0FmeW1T8ghLt4GD2IrRNLbJ1YJrWbRJ4ljy3JW1h7fC1rjq9h1bFVgKPDuVdEL3o27EmrkFYYlMHNkQtRtsq8a2ge0BsIA5KB5wAPAK31e87bR98BbsZx++jdZTULgTQNiapHa82fGX+y9vhaVh9bzY6UHWg04T7h9IjoQc8GPelSvwt+Hn7uDlXUYPJAmRBXUXpBOutPrGfNsTVsOLmBHEsOJoOJDnU60DOiJz0jetIosJG7wxRViNYai01jttkxW+1YnO+FxT5bbHbqBHrTMKR8AytKIhDCTSx2C9vObGPt8bWsPb6WQ5mHAGgU2IgeDXoQVyeO9rXby1zNVZDWmgKLnTyzlTyzjXyLjTyzjTyzldzCkt/zzLbzFXmxCtxi046K3Wan0GKj0GqnwGKjoNhnuwtV8cReTXlyYMty/R5JBEJUEcezjzuSwom1bDm9hUJbIQCRgZGOPojajn6ICP8IGQ+pBHa7ptBqJ9/iqJjzzVbyzXZnJW2loKiytl3wOd9sLarIC62OCvriCttsc3zPN9vJN1vJs9i4nOrR28OAj4cRT5MBT5MBD6MBT6Pz3WTAw6jwNBnxNhnw8nC8e3sY8fY4927E07lt0f4mA55GVfT9uhBfGoWWr4lREoEQVZDZZmZP2h4SzySSmJxI4plEss3ZANT2qU37Ou2LEkPzWs0xGoxujvjy2O2aXLOVnEIr2QVWsgssznfHstxCx3tOgZVcs2N5bqHj7DrfYqPQaqPAcv7MucBZeV8uT5Ojgvb1NOLjacTbZMTjogrW02hwLnNUyr6e57f39TDi62lyfPZ0fPb3MuHrZcTP0/Hu62HEZKzaNwZIIhCiGrBrOwcyDjiSgjMxJOclA+Dv4U9M7RjiajuakqLCoyplZjarzU6u2UZuoZU8s5WcQltRhZ1baC1al1t4vuLOKf4qOL8ux2x16Yza19OIv5ejcvX3NjkqYOcZ8rkzZi+TES8PA94mY1FF7ePhqKiL3s99Llbp+1SDCvpqkUQgRDWkteZU7qmiK4bfz/xe9LSzh8GDtmFt6VCnA7G142ga2JYCs4mzeWbO5po5m2dxVtxW8s3n27bzzDbnGXcJ7dzO9m1XKAX+no6K29/LhJ+XiQBvE36e5z8HejvWB3h7EOB89/c6v9zPy7G90SBNYFeDJAIhqjCtHe3eWfkWsgosZOZbyXI2o2TlO98LLGQXWEjPP8upgn2k2faTwx9YTEdB2dHagL2gAdbcJtjymmDLbwR2b8BRafs5mzb8PI34eDrOuh0VsaOpw8/L+e5pxNe53M/Lsfxc5X7uu7+XCW+TEYNU4NVKVX2yWIhrjsVmd56VW0jLLSQjz3LBWfrZPHPRssw8R8WflW/FbCv9TNxkUAT6eDjPtFsT4R1NLV8P/H3sWEyHyNT7OG3ew0nfX7DpNRgw0DioKW3D2hITHkXbsLY0C26Gh8HjKv0lRHUiiUCIEtjt2lGB55nJzHdU1pnnztjzLGTmO15n8yyk5xZyNs9CWk4hWQXWS5bp62kk2NeTWr4ehPh50qCWD0E+HgR4exDoYyLQ24NAHw8CvU3n370d6709DKXcRdSx6FO+NZ/tKdvZmryVnak7WX18Fd8c/BoAL6MXLUNa0jasLW1C2xAREEEd3zqE+/7/9s48OO6zvOOfZ3e10l5aHavb1mVbju2cJpgQ0iQEcnDDQMs1HC0z6YSmQDshwHRKgaEzBUo5CqUNIZABGiiUDAlHONOQQEhwSOJDTmJZtiTrWt3SHtrVat/+8f4krWTZsYWlXXufz8w777E//fa772rf571+z1ujBqLI0akhpahIpucZjaUYiaUYnbFxdDpFdCbFyMws0RmbH42lyJxiY7evdwBlfgAAFQRJREFUxE3YV0JlwEtVoISqQClVfid28pV++/pC419WsvG7fowxHI8d58DogcVwaPwQyUxy8RpBiPgi1AfqqfPXUReooynYxI6qHeyo3qFPRJ8n6BqBct6SzRqmknYaZjSWZiyWzkmnGIulbaPvNPzx9Pyq96kOeKkJlVJbXkZtqHQxVAa8hH0lhH22tx72lVBeVoLXc+7uRMlkM/RO9zIYH2QoPsRwYnhZPBQfIpFJANZItIXb2FW9i12RXeyq3sX2qu34PL48fwrlTNE1AuWcwhhDLJVhNJa2vfeZFcEpi87MMhZLr9pzF4Eqv5eqgJdIsJRLNlUQCZYSCdl8TbB0Wb6kiLYYelwe2ivaaa9oX/V1Ywxjs2N0jnVycOwgnaOdPDr4KPd33w+AW9y0hdvYWrHVhsqtbKvYRlOw6Zx71kGx6IhA2VBm5+bpn0wy4IT+iSTRmZQzXZNm1EmnVtnG6HYJkaDTkIecxtyJq53y6qCXamdaRvePn12iiSgHRw9yYOwAz40/x+HJw/THljzHl7nLaAu3sa1yGx2VHewKNbPDHSKQmIDpASf0Q2wYysJQ0ZwTWiC8CTxreDYim4VsBrJzMD8H82lIxyAdd0JuOm57CaXlUBpaEcrBGwRxOfdzgsnm5OdzyhbS8za9UAaA064utq857ay47Xu4XDZezLut9tTMyUP7NXDBq9b0/emIQNkw5uaz9E8k6RlP0DueoHcsTt94koEp2+iPxdPLrncJVC/0zoNetkQCREKliw1+JFhKbblt7Cv93rO7ZdEY+8N1n+HPYD4D8REbSoMQaoSSstN/z9S0bRRjwzA7veLHPrWUzlj3E4gAsjwWl2305pJOSEBm1sZzSZibtZ+rxO8EX07sA0+ZbcTm0/Z95tM56TnbqK6g1gkvXfwsWRLGTbcry2GXocs1S1eyk0dHOrnPbb8nMYa2uQy7Uml2pdPsdAXYXlaDf/Q5OHiv1ZBLqAHKG+3nXGzYncZ9Qdd82n5vC3lz5k8bn3OI2xqrQGTNhuBUqCFQzoj5rCE6M8vAZJLjE0kGJmfpm0jQO5agZzzOwOQs8zlTNaUeF5sqfTRV+tnVWE5ThY/GCt9iXB8uWz4tk81CchxiUYj3QWIMJryQKF/qtS304Ep8TuN4GiTGIdoJw50QPejEhyA9A6Vh8FeCvxp8VeCvWoozKYgNwczwUhwfYVkPD8BXaQ1CqB7KG2zaXw2J0aWe8EKvOB07uU6Pb+nzecrs+xhzYmyy4PZaA1Tit1o9ZUuN/UJDP5fIMQ5JmJ2EmUGbdpeAu9TGnlL7N2Vhe1+X59R1awy43PjFxYUIF8pC79YFAqOeMjq9bg6aWTrT4/w+1sf9qXEAXDJDc10zW8LX0u6rYas7yJZ5oXU2TulUv60rkSUdbq+jtQRcTuz22h70Qj437fbann1pELwBm/YGbCgJ2DpMzViDfEKve9r5bB4nuJdicS/lxW179Itp91IZTr0t1l9OfuG7WwgLI4mFUYXbu3yEspb/9TWgU0PKMowxjMbS9I7H6RlL0DOWoG88Qf9kkv7JJENTsyfMyVf4S2ip8tNcHXBiPy1VfloqvNS6pnElx2wDNDsFyckT0/FRJ0RtbFZf0D0Bcdsfe4nfach8Ni7xLeXnU7bBn8k586isAup2Qe1O21gnJ6zBSY5bg5Ech8SENRLigkAthOogWL88DtRAKgYzAzA9CDNDS+l41P7AxbXUyy1vhPKmpXyo3ja8udMSnvP32MtoIrq47tA10UXXZBd9M33MO9+3S1w0h5ppD7fTEm6htbyV5lAzLeUtRHwRdcL3J6K7hpRlGGMYi6fpHonTPRLj6GicY2PxxUY/d2eNiKE9ZNgaNrQEDU2BLI3+LHVlc9R4M1SWzFGWmbENXyxqpzsW4sTYKVSIbQR9FbYxDtRCsMbGgZqcdMROAeT22Fb25OaStueemV0Kc04sLqi5AOp2Qu0uG4caTq93lUk7PcA1LIDOZ6yxKwuf+dRTEZGeT3Ns+hjdk910TXbRPdXNkckj9M30MZczPeX3+Gkpb6G53BqG9nA77eF2WsOtuoPpNMnn4fU3AV8A3MCdxph/WfH6u4HPsHRW8ZeMMXee6p5qCE4fYwyDU7Mc6J/icDRG90icIyMxukdiTM9mcJGlTQa5xNPDBf4YzaVx6j0xIjJNeXYSX3ocz+wYMp9+/jfzlEGwzgm1OXEt+CO2wS+rWGr8vSFnGK0oJzKfnWcwPkjvdC/Hpo/RO9NLz3QPvdO99Mf6F0cRgtAYbFw0DO0V7bSWt9IUbKLGX6NHheaQl8ViEXEDXwauB44DfxCR+4wxnSsu/a4x5tb10lEsGGPon0xyoH+aA/1T7O+f4kD/1OLirJDlBaEJXh48zmU1x9gyd5hI7Fk8mbi9QQrIlNqGOxCBQBMELrVpf/XS1MXCXGtpcCm/MJepQ3flLOF2udkU2sSm0CaubLpy2Wvp+TS907129DB1hKOTR+me6ubxoccXz3cA65ivMdhIU7BpWWgINlDnryPii+Bx6WgN1nexeA/QZYzpBnAOqX8dsNIQKGdCJgUTx5g8fojhowdJDT9HyWQ3ntQkmayhBaEZ4fWOO96yGsc1b7wXSc3ABLb3Xn8xdLwdGi+DhkvsFj5vUBtzpeDxur1srbTPL+Qyn51nID5Az3QPA7EBjseO0z/TT3+sn0Njh5hITSy73iUuIr6IfZraeaJ6weVGra+WGn8NNb4aAiWB8359Yj0NQRPQl5M/DrxoleveKCJXA88Bf2eM6Vt5gYjcDNwM0NzcvA5SC5DsPIx1weA+UsefJN63H/fEEUKzg7jIUgFUAGOmnCFPE6lQi+OvxkOo1HHtm7vLpP0K2+g3XmbnzHXeWjnPcLvcbA5tZnNo86qvx+fi9Mf6F5+iHo4PL8bdU908Ovgo8bn4CX/n8/io9dcS8UWo9dfSWt5Ke7idtnAbreHWdTkXYqPJd2twP3CPMSYlIn8N3A1ct/IiY8wdwB1g1wg2VuIGkE7AyCEY2g+D+5jrfwqJduKZd/zBmBIGTBPdppmJsqtwRbYS3rSDzVsv4oK2zezy6tOcivJ8BEoCdFR20FHZcdJrYukY0WSU0cQo0WSUkcQII8kRRhIjRBNR9o3s44GjD2Cc7cMucbEpuGnZ+kRlWSXh0jDh0jAVpRWUe8sLfgpqPdX1A7mmeRNLi8IAGGNyt5XcCXx6HfXkn2wWJo46+9kP2hDtxIx3I85DMXH87M+2cDB7Lc+52qD+Ypq2XsIL2mu5dlOY8jL1Eqko60XQGyToDdIeXt39BsBsZpae6Z7FHU7dU90cnTrKIwOPkFn5gJxDqCREuDRMla+KhkADDYEG6gP11AfqF/MVpRV5m4JaT0PwB2CbiLRhDcBbgLflXiAiDcaYhQ3erwUOraOejccYGD4Az/4UDv/CpuesMy+DMFnWxKHsZh6fu5hnss0cK9lCfct29rRX86K2at7RFD6nnZspyvlImaeM7VXb2V61fVn5XHaO4fgwk6lJJlOTTKWmlsWTqUnGk+M8M/4MD/Y+SDq7fDdembtscZ2izl9Hrb+WuoCN6/311AXqqCqrWpedUOtmCIwxGRG5FfgZdvvoXcaYgyLyCWCvMeY+4H0i8logA4wD714vPRtGJg09j9jG/9mfwlQfIKTqL+No4xt4LN7AT0eqeDpVTzrtY3dzBddcUcMt22rY1Viu/nEU5RylxFWyuNPp+TDGMJGasB5gY0MMJYYYiA0QTUQZTgzzxPATRJPRE0YY79j5Dm5/4e1nXbs+UHY2SMdto//Mj6Hrl/aBJ4+PZPPV/MH7Ir4W3cZDA3Yev6nCx9UdNVzTEeHKrRGd6lEUZVWyJsv47Lg1Ds7CdkdlB7vrdq/pfup0bj3IpOHIr2D/9+HZn9gpn0AtyY7X8Fv3Hu4aaOZ3nXax96KmMB95RQMv21HHlprzfyuaoih/OgvbWyO+CDurd67re6khOBOyWej5Lez/HnT+0PrJ8VUyd+Ff8HDpNdzZU8/v906QNbC9zsNtN3Tw6osbaY3oCU+KohQuaghOh+Qk/P4/4I/ftE7FSgJwwasYbnk1dw608p0/DjEzm6EtkubWl27l1Zc00lEXyrdqRVGU00INwalIx+Gx/4LffsH2/rfdSPaGT/Ib2c3XHx/hoe+P4HH1c9OF9bzzxa28sLVSp30URTnnUEOwGpkUPPEN+M2/Wq+a225k5srbuaevkm/9tJfe8U5qQ6V84OXbeOueZurKT/NQEkVRlAJEDUEu8xl4+h546FN222fLVfTdcAdf6Y7wg7uOMzs3zJ7WKm6/aTs37qovqnNuFUU5f1FDANYAHLwXHvoXGOvCNO7m6cs+wWe7Gnn4njG8nuO84dIm3v2SVnY0lOdbraIoylmluA3B/Bzs+y48/FkY7yZbs4P/u/RzfPJwG90PJKgrj/HBG7fz1j3NVAXO35OjFEUpborTEGRS8OS34JHPw1Qvpv5iHtj5GT7UuZnpviyXbvbyhes7eOVFDTr9oyjKeU9xGYJ0Av54t90FNDMITZdzZM/HeO9jEZ49FuP6nTXccu0WdjdX5lupoijKhlE8huC5n8MP3wvxEWh5CclXfYlPPVvP3T/qob48w1ffeTnX76zLt0pFUZQNp3gMQWUr1F8Ef3Ybv0xs5R/vPcDQdA/vvKKF227cTkh9/iiKUqQUjyGo6SD6unv4+P2d/Hj/XjrqgnzpbVfyghadBlIUpbgpGkPw4DNR3vedJ0llstx2Qwc3X71Fff0riqJQRIagLRJgd3Ml//SanbTXBPMtR1EUpWBY1y6xiNwkIs+KSJeIfHiV10tF5LvO64+JSOt6aWmNBLj7r/aoEVAURVnBuhkCEXEDXwZeAewE3ioiK51qvweYMMZsBT4HfGq99CiKoiirs54jgj1AlzGm2xiTBr4DvG7FNa8D7nbS3wdeJuq+U1EUZUNZT0PQBPTl5I87ZateY4zJAFNA9cobicjNIrJXRPaOjIysk1xFUZTi5JzYNmOMucMYc7kx5vKampp8y1EURTmvWE9D0A9szslvcspWvUZEPEAYGFtHTYqiKMoK1tMQ/AHYJiJtIuIF3gLct+Ka+4B3Oek3Ab82xph11KQoiqKsYN2eIzDGZETkVuBngBu4yxhzUEQ+Aew1xtwHfA34poh0AeNYY6EoiqJsIOv6QJkx5ifAT1aUfTQnPQv8+XpqUBRFUU6NnGszMSIyAvSs8c8jwOhZlHM2UW1ro5C1QWHrU21r41zV1mKMWXW3zTlnCP4URGSvMebyfOtYDdW2NgpZGxS2PtW2Ns5HbefE9lFFURRl/VBDoCiKUuQUmyG4I98CToFqWxuFrA0KW59qWxvnnbaiWiNQFEVRTqTYRgSKoijKCtQQKIqiFDlFYwie75CcfCIix0Rkv4g8JSJ786zlLhGJisiBnLIqEfmFiBx24rwc9HwSbR8TkX6n7p4SkVfmSdtmEXlQRDpF5KCIvN8pz3vdnUJb3utORMpE5HERedrR9nGnvM05rKrLObzKW0DaviEiR3Pq7dKN1paj0S0iT4rIj5z82urNGHPeB6yLiyNAO+AFngZ25ltXjr5jQCTfOhwtVwO7gQM5ZZ8GPuykPwx8qoC0fQy4rQDqrQHY7aRDwHPYA5nyXnen0Jb3ugMECDrpEuAx4Argf4C3OOX/CdxSQNq+Abwp3/9zjq6/B/4b+JGTX1O9FcuI4HQOyVEAY8xvsH6fcsk9QOhu4PUbKsrhJNoKAmPMoDHmj056BjiEPW8j73V3Cm15x1hiTrbECQa4DntYFeSv3k6mrSAQkU3Aq4A7nbywxnorFkNwOofk5BMD/FxEnhCRm/MtZhXqjDGDTnoIqMunmFW4VUT2OVNHeZm2ysU5e/sybA+yoOpuhTYogLpzpjeeAqLAL7Cj90ljD6uCPP5eV2ozxizU2z879fY5ESnNhzbg88DtQNbJV7PGeisWQ1DoXGWM2Y093/lvROTqfAs6GcaOOQumVwR8BdgCXAoMAp/NpxgRCQL/C3zAGDOd+1q+624VbQVRd8aYeWPMpdgzS/YAF+RDx2qs1CYiFwIfwWp8IVAFfGijdYnIq4GoMeaJs3G/YjEEp3NITt4wxvQ7cRS4F/tjKCSGRaQBwImjedaziDFm2PmxZoGvkse6E5ESbEP7bWPMD5zigqi71bQVUt05eiaBB4EXAxXOYVVQAL/XHG03OVNtxhiTAr5OfurtJcBrReQYdqr7OuALrLHeisUQnM4hOXlBRAIiElpIAzcAB079VxtO7gFC7wJ+mEcty1hoZB3eQJ7qzpmf/RpwyBjzbzkv5b3uTqatEOpORGpEpMJJ+4DrsWsYD2IPq4L81dtq2p7JMeyCnYPf8HozxnzEGLPJGNOKbc9+bYx5O2utt3yvem9UAF6J3S1xBPiHfOvJ0dWO3cX0NHAw39qAe7DTBHPYOcb3YOcefwUcBn4JVBWQtm8C+4F92Ea3IU/arsJO++wDnnLCKwuh7k6hLe91B1wMPOloOAB81ClvBx4HuoDvAaUFpO3XTr0dAL6Fs7MoXwG4lqVdQ2uqN3UxoSiKUuQUy9SQoiiKchLUECiKohQ5aggURVGKHDUEiqIoRY4aAkVRlCJHDYGirEBE5nM8Sz4lZ9FbrYi05npPVZRCwPP8lyhK0ZE01q2AohQFOiJQlNNE7LkRnxZ7dsTjIrLVKW8VkV87Tsh+JSLNTnmdiNzr+LN/WkSudG7lFpGvOj7uf+48taooeUMNgaKciG/F1NCbc16bMsZcBHwJ6/0R4N+Bu40xFwPfBr7olH8ReMgYcwn2HIWDTvk24MvGmF3AJPDGdf48inJK9MliRVmBiMSMMcFVyo8B1xljuh0nbkPGmGoRGcW6Z5hzygeNMRERGQE2GeucbOEerVh3xtuc/IeAEmPMJ9f/kynK6uiIQFHODHOS9JmQyknPo2t1Sp5RQ6AoZ8abc+JHnfTvsB4gAd4OPOykfwXcAosHnIQ3SqSinAnaE1GUE/E5p1It8IAxZmELaaWI7MP26t/qlP0t8HUR+SAwAvylU/5+4A4ReQ+2538L1nuqohQUukagKKeJs0ZwuTFmNN9aFOVsolNDiqIoRY6OCBRFUYocHREoiqIUOWoIFEVRihw1BIqiKEWOGgJFUZQiRw2BoihKkfP/3r1Zql+BUyoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to Load Weights and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZraWGjS18ymQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "    \n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2,2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    t = BatchNormalization()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    t = BatchNormalization()(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    sgd=SGD(learning_rate=0.01,clipnorm=1,momentum=0.9,name='sgd')\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net() # or create_plain_net()\n",
    "\n",
    "model.load_weights('../weights/ResNet_BatchNorm_SGD.hdf5')\n",
    "\n",
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNet_Batch_NormSGD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
