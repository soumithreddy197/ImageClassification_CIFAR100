{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NxcM7lbVYSTV"
   },
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "#Create Model\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return relu\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    #y = Dropout(0 if not downsample else 0.5)(y)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "\n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2, 2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    t = Dropout(0.5)(t)\n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    sgd=SGD(learning_rate=0.01,clipnorm=1,momentum=0.91,name='sgd')\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet taken and modified from https://towardsdatascience.com/building-a-resnet-in-keras-e8f1322a49ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "2V0fjB-gYiYO",
    "outputId": "3829bcd3-9585-4e45-fc3d-81225a3e48ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 3)    12          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 64)   1792        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 32, 32, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 32, 32, 64)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 64)   0           re_lu_17[0][0]                   \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 32, 32, 64)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 32, 32, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   36928       re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 64)   0           re_lu_19[0][0]                   \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 32, 32, 64)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 128)  73856       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 128)  8320        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 16, 16, 128)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 128)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           dropout_4[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 16, 16, 128)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 16, 16, 128)  0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  147584      re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           re_lu_23[0][0]                   \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 16, 16, 128)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 256)    295168      re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 256)    33024       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 8, 8, 256)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8, 8, 256)    0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           dropout_5[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 8, 8, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 8, 8, 256)    0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 256)    590080      re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           re_lu_27[0][0]                   \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 8, 8, 256)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 512)    1180160     re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 4, 4, 512)    131584      re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 4, 4, 512)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 4, 4, 512)    0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 512)    0           dropout_6[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 4, 4, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 4, 4, 512)    0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 4, 512)    2359808     re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           re_lu_31[0][0]                   \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 4, 4, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 4, 4, 512)    0           re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          51300       dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,478,000\n",
      "Trainable params: 11,477,994\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.4828 - accuracy: 0.0185\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.03780, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 4.4828 - accuracy: 0.0185 - val_loss: 4.3155 - val_accuracy: 0.0378\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.1988 - accuracy: 0.0485\n",
      "Epoch 00002: val_accuracy improved from 0.03780 to 0.06810, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 4.1988 - accuracy: 0.0485 - val_loss: 4.0544 - val_accuracy: 0.0681\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.9524 - accuracy: 0.0824\n",
      "Epoch 00003: val_accuracy improved from 0.06810 to 0.10120, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 3.9524 - accuracy: 0.0824 - val_loss: 3.8393 - val_accuracy: 0.1012\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.7647 - accuracy: 0.1127\n",
      "Epoch 00004: val_accuracy improved from 0.10120 to 0.13110, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 3.7647 - accuracy: 0.1127 - val_loss: 3.6507 - val_accuracy: 0.1311\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.6073 - accuracy: 0.1387\n",
      "Epoch 00005: val_accuracy improved from 0.13110 to 0.16270, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 3.6073 - accuracy: 0.1387 - val_loss: 3.5056 - val_accuracy: 0.1627\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.4234 - accuracy: 0.1741\n",
      "Epoch 00006: val_accuracy improved from 0.16270 to 0.21580, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 3.4234 - accuracy: 0.1741 - val_loss: 3.1940 - val_accuracy: 0.2158\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.2585 - accuracy: 0.2010\n",
      "Epoch 00007: val_accuracy improved from 0.21580 to 0.24590, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 3.2585 - accuracy: 0.2010 - val_loss: 3.0671 - val_accuracy: 0.2459\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 3.1276 - accuracy: 0.2279\n",
      "Epoch 00008: val_accuracy improved from 0.24590 to 0.26870, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 3.1276 - accuracy: 0.2279 - val_loss: 2.9375 - val_accuracy: 0.2687\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.9918 - accuracy: 0.2509\n",
      "Epoch 00009: val_accuracy improved from 0.26870 to 0.29440, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.9918 - accuracy: 0.2509 - val_loss: 2.7762 - val_accuracy: 0.2944\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.8553 - accuracy: 0.2769\n",
      "Epoch 00010: val_accuracy improved from 0.29440 to 0.32230, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.8553 - accuracy: 0.2769 - val_loss: 2.6553 - val_accuracy: 0.3223\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.7339 - accuracy: 0.3017\n",
      "Epoch 00011: val_accuracy improved from 0.32230 to 0.34860, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.7339 - accuracy: 0.3017 - val_loss: 2.5040 - val_accuracy: 0.3486\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.6213 - accuracy: 0.3244\n",
      "Epoch 00012: val_accuracy improved from 0.34860 to 0.36160, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.6213 - accuracy: 0.3244 - val_loss: 2.4192 - val_accuracy: 0.3616\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.5140 - accuracy: 0.3467\n",
      "Epoch 00013: val_accuracy improved from 0.36160 to 0.38780, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.5140 - accuracy: 0.3467 - val_loss: 2.3147 - val_accuracy: 0.3878\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.4079 - accuracy: 0.3683\n",
      "Epoch 00014: val_accuracy improved from 0.38780 to 0.40720, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.4079 - accuracy: 0.3683 - val_loss: 2.2120 - val_accuracy: 0.4072\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.3290 - accuracy: 0.3838\n",
      "Epoch 00015: val_accuracy improved from 0.40720 to 0.42490, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 2.3290 - accuracy: 0.3838 - val_loss: 2.1466 - val_accuracy: 0.4249\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.2444 - accuracy: 0.4052\n",
      "Epoch 00016: val_accuracy improved from 0.42490 to 0.43030, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 2.2444 - accuracy: 0.4052 - val_loss: 2.1488 - val_accuracy: 0.4303\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.1602 - accuracy: 0.4231\n",
      "Epoch 00017: val_accuracy improved from 0.43030 to 0.43480, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 2.1602 - accuracy: 0.4231 - val_loss: 2.1334 - val_accuracy: 0.4348\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0833 - accuracy: 0.4378\n",
      "Epoch 00018: val_accuracy improved from 0.43480 to 0.46210, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 2.0833 - accuracy: 0.4378 - val_loss: 1.9801 - val_accuracy: 0.4621\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.0155 - accuracy: 0.4531\n",
      "Epoch 00019: val_accuracy improved from 0.46210 to 0.47130, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 2.0155 - accuracy: 0.4531 - val_loss: 1.9593 - val_accuracy: 0.4713\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.9515 - accuracy: 0.4679\n",
      "Epoch 00020: val_accuracy improved from 0.47130 to 0.47610, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 1.9515 - accuracy: 0.4679 - val_loss: 1.9242 - val_accuracy: 0.4761\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8913 - accuracy: 0.4805\n",
      "Epoch 00021: val_accuracy improved from 0.47610 to 0.49630, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 1.8913 - accuracy: 0.4805 - val_loss: 1.8248 - val_accuracy: 0.4963\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.8344 - accuracy: 0.4928\n",
      "Epoch 00022: val_accuracy improved from 0.49630 to 0.50010, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 93s 238ms/step - loss: 1.8344 - accuracy: 0.4928 - val_loss: 1.8206 - val_accuracy: 0.5001\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7735 - accuracy: 0.5090\n",
      "Epoch 00023: val_accuracy did not improve from 0.50010\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.7735 - accuracy: 0.5090 - val_loss: 1.9365 - val_accuracy: 0.4800\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7274 - accuracy: 0.5213\n",
      "Epoch 00024: val_accuracy improved from 0.50010 to 0.53010, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 1.7274 - accuracy: 0.5213 - val_loss: 1.7165 - val_accuracy: 0.5301\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6755 - accuracy: 0.5317\n",
      "Epoch 00025: val_accuracy did not improve from 0.53010\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.6755 - accuracy: 0.5317 - val_loss: 1.7973 - val_accuracy: 0.5170\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6354 - accuracy: 0.5414\n",
      "Epoch 00026: val_accuracy did not improve from 0.53010\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.6354 - accuracy: 0.5414 - val_loss: 1.7422 - val_accuracy: 0.5254\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5950 - accuracy: 0.5527\n",
      "Epoch 00027: val_accuracy improved from 0.53010 to 0.54050, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 1.5950 - accuracy: 0.5527 - val_loss: 1.6806 - val_accuracy: 0.5405\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5577 - accuracy: 0.5588\n",
      "Epoch 00028: val_accuracy improved from 0.54050 to 0.54410, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 1.5577 - accuracy: 0.5588 - val_loss: 1.6659 - val_accuracy: 0.5441\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.5067 - accuracy: 0.5718\n",
      "Epoch 00029: val_accuracy improved from 0.54410 to 0.54490, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.5067 - accuracy: 0.5718 - val_loss: 1.6390 - val_accuracy: 0.5449\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4728 - accuracy: 0.5816\n",
      "Epoch 00030: val_accuracy did not improve from 0.54490\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.4728 - accuracy: 0.5816 - val_loss: 1.6593 - val_accuracy: 0.5428\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4335 - accuracy: 0.5913\n",
      "Epoch 00031: val_accuracy improved from 0.54490 to 0.55590, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.4335 - accuracy: 0.5913 - val_loss: 1.6396 - val_accuracy: 0.5559\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4092 - accuracy: 0.5979\n",
      "Epoch 00032: val_accuracy did not improve from 0.55590\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.4092 - accuracy: 0.5979 - val_loss: 1.7145 - val_accuracy: 0.5491\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3615 - accuracy: 0.6084\n",
      "Epoch 00033: val_accuracy did not improve from 0.55590\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.3615 - accuracy: 0.6084 - val_loss: 1.7736 - val_accuracy: 0.5308\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3484 - accuracy: 0.6103\n",
      "Epoch 00034: val_accuracy improved from 0.55590 to 0.57290, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.3484 - accuracy: 0.6103 - val_loss: 1.5888 - val_accuracy: 0.5729\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.3056 - accuracy: 0.6234\n",
      "Epoch 00035: val_accuracy improved from 0.57290 to 0.58270, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 1.3056 - accuracy: 0.6234 - val_loss: 1.5296 - val_accuracy: 0.5827\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2882 - accuracy: 0.6286\n",
      "Epoch 00036: val_accuracy did not improve from 0.58270\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.2882 - accuracy: 0.6286 - val_loss: 1.6087 - val_accuracy: 0.5674\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2467 - accuracy: 0.6348\n",
      "Epoch 00037: val_accuracy did not improve from 0.58270\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.2467 - accuracy: 0.6348 - val_loss: 1.5984 - val_accuracy: 0.5685\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2162 - accuracy: 0.6463\n",
      "Epoch 00038: val_accuracy did not improve from 0.58270\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.2162 - accuracy: 0.6463 - val_loss: 1.5693 - val_accuracy: 0.5702\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1964 - accuracy: 0.6505\n",
      "Epoch 00039: val_accuracy improved from 0.58270 to 0.58820, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.1964 - accuracy: 0.6505 - val_loss: 1.5199 - val_accuracy: 0.5882\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1602 - accuracy: 0.6622\n",
      "Epoch 00040: val_accuracy improved from 0.58820 to 0.59270, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.1602 - accuracy: 0.6622 - val_loss: 1.4925 - val_accuracy: 0.5927\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1309 - accuracy: 0.6646\n",
      "Epoch 00041: val_accuracy did not improve from 0.59270\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.1309 - accuracy: 0.6646 - val_loss: 1.6602 - val_accuracy: 0.5720\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1066 - accuracy: 0.6718\n",
      "Epoch 00042: val_accuracy did not improve from 0.59270\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.1066 - accuracy: 0.6718 - val_loss: 1.5597 - val_accuracy: 0.5821\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0835 - accuracy: 0.6766\n",
      "Epoch 00043: val_accuracy did not improve from 0.59270\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.0835 - accuracy: 0.6766 - val_loss: 1.6271 - val_accuracy: 0.5741\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0648 - accuracy: 0.6833\n",
      "Epoch 00044: val_accuracy improved from 0.59270 to 0.60210, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 1.0648 - accuracy: 0.6833 - val_loss: 1.5079 - val_accuracy: 0.6021\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0305 - accuracy: 0.6919\n",
      "Epoch 00045: val_accuracy did not improve from 0.60210\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.0305 - accuracy: 0.6919 - val_loss: 1.5231 - val_accuracy: 0.5992\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.0148 - accuracy: 0.6979\n",
      "Epoch 00046: val_accuracy improved from 0.60210 to 0.60310, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 1.0148 - accuracy: 0.6979 - val_loss: 1.4814 - val_accuracy: 0.6031\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9951 - accuracy: 0.7012\n",
      "Epoch 00047: val_accuracy did not improve from 0.60310\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 0.9951 - accuracy: 0.7012 - val_loss: 1.5302 - val_accuracy: 0.5960\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9702 - accuracy: 0.7092\n",
      "Epoch 00048: val_accuracy did not improve from 0.60310\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 0.9702 - accuracy: 0.7092 - val_loss: 1.5906 - val_accuracy: 0.5974\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9534 - accuracy: 0.7136\n",
      "Epoch 00049: val_accuracy did not improve from 0.60310\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 0.9534 - accuracy: 0.7136 - val_loss: 1.5596 - val_accuracy: 0.5947\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9367 - accuracy: 0.7185\n",
      "Epoch 00050: val_accuracy improved from 0.60310 to 0.62270, saving model to ResNet_DropOUT_Adam.hdf5\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 0.9367 - accuracy: 0.7185 - val_loss: 1.4678 - val_accuracy: 0.6227\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.9085 - accuracy: 0.7243\n",
      "Epoch 00051: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 0.9085 - accuracy: 0.7243 - val_loss: 1.6134 - val_accuracy: 0.5982\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8933 - accuracy: 0.7297\n",
      "Epoch 00052: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 0.8933 - accuracy: 0.7297 - val_loss: 1.6614 - val_accuracy: 0.5835\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8755 - accuracy: 0.7318\n",
      "Epoch 00053: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 0.8755 - accuracy: 0.7318 - val_loss: 1.5648 - val_accuracy: 0.6028\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8634 - accuracy: 0.7373\n",
      "Epoch 00054: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 0.8634 - accuracy: 0.7373 - val_loss: 1.5620 - val_accuracy: 0.6088\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8384 - accuracy: 0.7447\n",
      "Epoch 00055: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 0.8384 - accuracy: 0.7447 - val_loss: 1.5931 - val_accuracy: 0.6031\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8214 - accuracy: 0.7485\n",
      "Epoch 00056: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 0.8214 - accuracy: 0.7485 - val_loss: 1.7934 - val_accuracy: 0.5772\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8055 - accuracy: 0.7534\n",
      "Epoch 00057: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 239ms/step - loss: 0.8055 - accuracy: 0.7534 - val_loss: 1.6110 - val_accuracy: 0.6099\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7844 - accuracy: 0.7575\n",
      "Epoch 00058: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 0.7844 - accuracy: 0.7575 - val_loss: 1.6686 - val_accuracy: 0.5933\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7728 - accuracy: 0.7625\n",
      "Epoch 00059: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 94s 240ms/step - loss: 0.7728 - accuracy: 0.7625 - val_loss: 1.6754 - val_accuracy: 0.5951\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.7644Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.62270\n",
      "391/391 [==============================] - 93s 239ms/step - loss: 0.7692 - accuracy: 0.7644 - val_loss: 1.5945 - val_accuracy: 0.6186\n",
      "Epoch 00060: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net() # or create_plain_net()\n",
    "model.summary()\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_data=ImageDataGenerator(rotation_range=20,horizontal_flip=True,width_shift_range=0.1,shear_range = 0.2,height_shift_range=0.1,zoom_range=0.2,brightness_range = (0.5, 1.5))\n",
    "aug_data.fit(x_train)\n",
    "\n",
    "# save model after each epoch\n",
    "checkpoint = ModelCheckpoint('ResNet_DropOUT_SGD.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128),batch_size=128, epochs=100, verbose=1, validation_data=(x_test, y_test),callbacks=[early,checkpoint])\n",
    "\n",
    "#model.fit(x=x_train,y=y_train,epochs=20,verbose=1,validation_data=(x_test, y_test),batch_size=128,callbacks=[checkpoint, tensorboard_callback,early]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "1aopKUwXYla-",
    "outputId": "0f012f3e-06fe-4583-e5bd-6b5cbbc20fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.637561927622072\n",
      "Recall: 0.6227\n",
      "Accuracy: 0.6227\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "nkGxwn-1x_dg",
    "outputId": "0ae0bf26-a397-4524-b07d-39e3ca4f14a7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell to Load Weights and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "edqxPCMGyB1J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.637561927622072\n",
      "Recall: 0.6227\n",
      "Accuracy: 0.6227\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU,LeakyReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, Dropout,ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "def relu_bn(inputs: Tensor) -> Tensor:\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return relu\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,strides= (1 if not downsample else 2),filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "    #y = Dropout(0 if not downsample else 0.5)(y)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,strides=1,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(y)\n",
    "\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,strides=2,filters=filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "\n",
    "def create_res_net():\n",
    "    \n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    num_filters = 64\n",
    "\n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,strides=1,filters=num_filters,padding=\"same\",kernel_initializer = glorot_uniform(seed=0))(t)\n",
    "    t = relu_bn(t)\n",
    "    \n",
    "    num_blocks_list = [2,2, 2,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    t = Dropout(0.5)(t)\n",
    "    t = AveragePooling2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    t = Dense(512,activation='relu')(t)\n",
    "    outputs = Dense(100, activation='softmax')(t)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    sgd=SGD(learning_rate=0.01,clipnorm=1,momentum=0.91,name='sgd')\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard,EarlyStopping\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train,100)\n",
    "y_test = to_categorical(Y_test,100)\n",
    "\n",
    "model = create_res_net() # or create_plain_net()\n",
    "\n",
    "model.load_weights('../weights/ResNet_DropOUT_SGD.hdf5')\n",
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_Dropout_SGD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
