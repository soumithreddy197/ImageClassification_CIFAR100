{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gTFjV5JIBNVp"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AEr4CvsgfazC"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "aug_data=ImageDataGenerator(\n",
    "        rotation_range=20,     #randomly rotate images in the range (20 degrees)\n",
    "        horizontal_flip=True,  #randomly flip images\n",
    "        width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
    "        shear_range = 0.2,     #Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "        height_shift_range=0.1,#randomly shift images vertically (fraction of total height)\n",
    "        zoom_range=0.2,        #Range for random zoom\n",
    "        brightness_range = (0.5, 1.5))   #Range for picking a brightness shift value\n",
    "aug_data.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PoOJQTekBUB_"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense,BatchNormalization,Activation,Dropout,LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "#import tensorflow as \n",
    "model = Sequential()\n",
    "\n",
    "# Creating first block- (2 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same', input_shape= (32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating second block- (2 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Creating third block- (3 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating fourth block- (3 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating fifth block- (3 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Flattening the pooled image pixels\n",
    "model.add(Flatten())\n",
    "\n",
    "# Creating 2 Dense Layers\n",
    "model.add(Dense(units= 512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units= 512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating an output layer\n",
    "model.add(Dense(units= 100, activation='softmax'))\n",
    "'''\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "gvs = optimizer.compute_gradients(cost)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs]\n",
    "train_op = optimizer.apply_gradients(capped_gvs)\n",
    "'''\n",
    "#adam=Adam(learning_rate=0.0001,clipnorm=1,name='adam')\n",
    "\n",
    "sgd=SGD(learning_rate=0.001,momentum=0.9,clipnorm=1,name='sgd')\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet taken and modified from https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "FcZs678WB7jp",
    "outputId": "af6b7cdc-1e77-46c4-b5b8-376077d45e0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 4.3023 - accuracy: 0.0701\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.12360, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 101s 259ms/step - loss: 4.3023 - accuracy: 0.0701 - val_loss: 3.9125 - val_accuracy: 0.1236\n",
      "Epoch 2/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.6976 - accuracy: 0.1508\n",
      "Epoch 00002: val_accuracy improved from 0.12360 to 0.18320, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 3.6976 - accuracy: 0.1508 - val_loss: 3.5277 - val_accuracy: 0.1832\n",
      "Epoch 3/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.4306 - accuracy: 0.1950\n",
      "Epoch 00003: val_accuracy improved from 0.18320 to 0.23090, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 3.4306 - accuracy: 0.1950 - val_loss: 3.2545 - val_accuracy: 0.2309\n",
      "Epoch 4/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.2293 - accuracy: 0.2286\n",
      "Epoch 00004: val_accuracy improved from 0.23090 to 0.26270, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 3.2293 - accuracy: 0.2286 - val_loss: 3.0832 - val_accuracy: 0.2627\n",
      "Epoch 5/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 3.0611 - accuracy: 0.2570\n",
      "Epoch 00005: val_accuracy did not improve from 0.26270\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 3.0611 - accuracy: 0.2570 - val_loss: 3.1106 - val_accuracy: 0.2526\n",
      "Epoch 6/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.9223 - accuracy: 0.2836\n",
      "Epoch 00006: val_accuracy improved from 0.26270 to 0.29760, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 2.9223 - accuracy: 0.2836 - val_loss: 2.8545 - val_accuracy: 0.2976\n",
      "Epoch 7/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.8009 - accuracy: 0.3085\n",
      "Epoch 00007: val_accuracy improved from 0.29760 to 0.33570, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 2.8009 - accuracy: 0.3085 - val_loss: 2.6973 - val_accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.6904 - accuracy: 0.3290\n",
      "Epoch 00008: val_accuracy improved from 0.33570 to 0.34380, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 2.6904 - accuracy: 0.3290 - val_loss: 2.6328 - val_accuracy: 0.3438\n",
      "Epoch 9/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5948 - accuracy: 0.3460\n",
      "Epoch 00009: val_accuracy improved from 0.34380 to 0.35020, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 2.5948 - accuracy: 0.3460 - val_loss: 2.5972 - val_accuracy: 0.3502\n",
      "Epoch 10/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.5053 - accuracy: 0.3648\n",
      "Epoch 00010: val_accuracy improved from 0.35020 to 0.37150, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 2.5053 - accuracy: 0.3648 - val_loss: 2.4884 - val_accuracy: 0.3715\n",
      "Epoch 11/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.4255 - accuracy: 0.3824\n",
      "Epoch 00011: val_accuracy improved from 0.37150 to 0.39820, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 2.4255 - accuracy: 0.3824 - val_loss: 2.3615 - val_accuracy: 0.3982\n",
      "Epoch 12/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.3432 - accuracy: 0.4027\n",
      "Epoch 00012: val_accuracy improved from 0.39820 to 0.39860, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 2.3432 - accuracy: 0.4027 - val_loss: 2.3494 - val_accuracy: 0.3986\n",
      "Epoch 13/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2725 - accuracy: 0.4131\n",
      "Epoch 00013: val_accuracy improved from 0.39860 to 0.41990, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 2.2725 - accuracy: 0.4131 - val_loss: 2.2488 - val_accuracy: 0.4199\n",
      "Epoch 14/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.2121 - accuracy: 0.4286\n",
      "Epoch 00014: val_accuracy did not improve from 0.41990\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 2.2121 - accuracy: 0.4286 - val_loss: 2.2528 - val_accuracy: 0.4186\n",
      "Epoch 15/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.1464 - accuracy: 0.4401\n",
      "Epoch 00015: val_accuracy did not improve from 0.41990\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 2.1464 - accuracy: 0.4401 - val_loss: 2.2739 - val_accuracy: 0.4130\n",
      "Epoch 16/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0962 - accuracy: 0.4547\n",
      "Epoch 00016: val_accuracy improved from 0.41990 to 0.43190, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 2.0962 - accuracy: 0.4547 - val_loss: 2.1868 - val_accuracy: 0.4319\n",
      "Epoch 17/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 2.0345 - accuracy: 0.4673\n",
      "Epoch 00017: val_accuracy improved from 0.43190 to 0.43460, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 2.0345 - accuracy: 0.4673 - val_loss: 2.1699 - val_accuracy: 0.4346\n",
      "Epoch 18/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9842 - accuracy: 0.4776\n",
      "Epoch 00018: val_accuracy improved from 0.43460 to 0.44220, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.9842 - accuracy: 0.4776 - val_loss: 2.1438 - val_accuracy: 0.4422\n",
      "Epoch 19/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.9336 - accuracy: 0.4893\n",
      "Epoch 00019: val_accuracy improved from 0.44220 to 0.47080, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.9336 - accuracy: 0.4893 - val_loss: 1.9838 - val_accuracy: 0.4708\n",
      "Epoch 20/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8902 - accuracy: 0.4967\n",
      "Epoch 00020: val_accuracy did not improve from 0.47080\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 1.8902 - accuracy: 0.4967 - val_loss: 2.1092 - val_accuracy: 0.4465\n",
      "Epoch 21/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8373 - accuracy: 0.5116\n",
      "Epoch 00021: val_accuracy improved from 0.47080 to 0.47400, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 1.8373 - accuracy: 0.5116 - val_loss: 1.9785 - val_accuracy: 0.4740\n",
      "Epoch 22/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.8006 - accuracy: 0.5193\n",
      "Epoch 00022: val_accuracy improved from 0.47400 to 0.49150, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 1.8006 - accuracy: 0.5193 - val_loss: 1.9088 - val_accuracy: 0.4915\n",
      "Epoch 23/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7624 - accuracy: 0.5271\n",
      "Epoch 00023: val_accuracy improved from 0.49150 to 0.49640, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 1.7624 - accuracy: 0.5271 - val_loss: 1.8762 - val_accuracy: 0.4964\n",
      "Epoch 24/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.7099 - accuracy: 0.5417\n",
      "Epoch 00024: val_accuracy did not improve from 0.49640\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.7099 - accuracy: 0.5417 - val_loss: 1.8773 - val_accuracy: 0.4959\n",
      "Epoch 25/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6778 - accuracy: 0.5478\n",
      "Epoch 00025: val_accuracy improved from 0.49640 to 0.50020, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.6778 - accuracy: 0.5478 - val_loss: 1.8887 - val_accuracy: 0.5002\n",
      "Epoch 26/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6508 - accuracy: 0.5545\n",
      "Epoch 00026: val_accuracy did not improve from 0.50020\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.6508 - accuracy: 0.5545 - val_loss: 1.9079 - val_accuracy: 0.4983\n",
      "Epoch 27/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.6200 - accuracy: 0.5619\n",
      "Epoch 00027: val_accuracy improved from 0.50020 to 0.52130, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.6200 - accuracy: 0.5619 - val_loss: 1.7987 - val_accuracy: 0.5213\n",
      "Epoch 28/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5822 - accuracy: 0.5704\n",
      "Epoch 00028: val_accuracy did not improve from 0.52130\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 1.5822 - accuracy: 0.5704 - val_loss: 1.7990 - val_accuracy: 0.5198\n",
      "Epoch 29/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5439 - accuracy: 0.5799\n",
      "Epoch 00029: val_accuracy improved from 0.52130 to 0.53400, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 1.5439 - accuracy: 0.5799 - val_loss: 1.7419 - val_accuracy: 0.5340\n",
      "Epoch 30/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.5215 - accuracy: 0.5850\n",
      "Epoch 00030: val_accuracy improved from 0.53400 to 0.54610, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.5215 - accuracy: 0.5850 - val_loss: 1.6829 - val_accuracy: 0.5461\n",
      "Epoch 31/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4829 - accuracy: 0.5973\n",
      "Epoch 00031: val_accuracy did not improve from 0.54610\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 1.4829 - accuracy: 0.5973 - val_loss: 1.8285 - val_accuracy: 0.5141\n",
      "Epoch 32/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4560 - accuracy: 0.6020\n",
      "Epoch 00032: val_accuracy did not improve from 0.54610\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.4560 - accuracy: 0.6020 - val_loss: 1.7414 - val_accuracy: 0.5324\n",
      "Epoch 33/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.4304 - accuracy: 0.6089\n",
      "Epoch 00033: val_accuracy did not improve from 0.54610\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 1.4304 - accuracy: 0.6089 - val_loss: 1.7051 - val_accuracy: 0.5407\n",
      "Epoch 34/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3918 - accuracy: 0.6171\n",
      "Epoch 00034: val_accuracy did not improve from 0.54610\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 1.3918 - accuracy: 0.6171 - val_loss: 1.7353 - val_accuracy: 0.5355\n",
      "Epoch 35/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3680 - accuracy: 0.6237\n",
      "Epoch 00035: val_accuracy did not improve from 0.54610\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 1.3680 - accuracy: 0.6237 - val_loss: 1.8416 - val_accuracy: 0.5205\n",
      "Epoch 36/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3401 - accuracy: 0.6290\n",
      "Epoch 00036: val_accuracy did not improve from 0.54610\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.3401 - accuracy: 0.6290 - val_loss: 1.7533 - val_accuracy: 0.5287\n",
      "Epoch 37/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3143 - accuracy: 0.6389\n",
      "Epoch 00037: val_accuracy did not improve from 0.54610\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.3143 - accuracy: 0.6389 - val_loss: 1.7127 - val_accuracy: 0.5440\n",
      "Epoch 38/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2952 - accuracy: 0.6410\n",
      "Epoch 00038: val_accuracy improved from 0.54610 to 0.55110, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.2952 - accuracy: 0.6410 - val_loss: 1.6649 - val_accuracy: 0.5511\n",
      "Epoch 39/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2669 - accuracy: 0.6472\n",
      "Epoch 00039: val_accuracy improved from 0.55110 to 0.55380, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.2669 - accuracy: 0.6472 - val_loss: 1.6619 - val_accuracy: 0.5538\n",
      "Epoch 40/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2519 - accuracy: 0.6520\n",
      "Epoch 00040: val_accuracy improved from 0.55380 to 0.55890, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.2519 - accuracy: 0.6520 - val_loss: 1.6518 - val_accuracy: 0.5589\n",
      "Epoch 41/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2261 - accuracy: 0.6594\n",
      "Epoch 00041: val_accuracy improved from 0.55890 to 0.57470, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.2261 - accuracy: 0.6594 - val_loss: 1.5661 - val_accuracy: 0.5747\n",
      "Epoch 42/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.2046 - accuracy: 0.6636\n",
      "Epoch 00042: val_accuracy did not improve from 0.57470\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.2046 - accuracy: 0.6636 - val_loss: 1.7220 - val_accuracy: 0.5459\n",
      "Epoch 43/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1784 - accuracy: 0.6713\n",
      "Epoch 00043: val_accuracy did not improve from 0.57470\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 1.1784 - accuracy: 0.6713 - val_loss: 1.6352 - val_accuracy: 0.5678\n",
      "Epoch 44/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1594 - accuracy: 0.6752\n",
      "Epoch 00044: val_accuracy did not improve from 0.57470\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 1.1594 - accuracy: 0.6752 - val_loss: 1.6292 - val_accuracy: 0.5650\n",
      "Epoch 45/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1379 - accuracy: 0.6814\n",
      "Epoch 00045: val_accuracy did not improve from 0.57470\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 1.1379 - accuracy: 0.6814 - val_loss: 1.6639 - val_accuracy: 0.5568\n",
      "Epoch 46/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1157 - accuracy: 0.6871\n",
      "Epoch 00046: val_accuracy improved from 0.57470 to 0.57650, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 1.1157 - accuracy: 0.6871 - val_loss: 1.5890 - val_accuracy: 0.5765\n",
      "Epoch 47/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0951 - accuracy: 0.6931\n",
      "Epoch 00047: val_accuracy improved from 0.57650 to 0.58310, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 1.0951 - accuracy: 0.6931 - val_loss: 1.5380 - val_accuracy: 0.5831\n",
      "Epoch 48/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0731 - accuracy: 0.6980\n",
      "Epoch 00048: val_accuracy did not improve from 0.58310\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 1.0731 - accuracy: 0.6980 - val_loss: 1.5897 - val_accuracy: 0.5774\n",
      "Epoch 49/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0587 - accuracy: 0.6992\n",
      "Epoch 00049: val_accuracy did not improve from 0.58310\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 1.0587 - accuracy: 0.6992 - val_loss: 1.6145 - val_accuracy: 0.5696\n",
      "Epoch 50/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0299 - accuracy: 0.7103\n",
      "Epoch 00050: val_accuracy did not improve from 0.58310\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.0299 - accuracy: 0.7103 - val_loss: 1.6199 - val_accuracy: 0.5684\n",
      "Epoch 51/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0234 - accuracy: 0.7093\n",
      "Epoch 00051: val_accuracy did not improve from 0.58310\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.0234 - accuracy: 0.7093 - val_loss: 1.6342 - val_accuracy: 0.5649\n",
      "Epoch 52/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0054 - accuracy: 0.7168\n",
      "Epoch 00052: val_accuracy did not improve from 0.58310\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 1.0054 - accuracy: 0.7168 - val_loss: 1.6508 - val_accuracy: 0.5640\n",
      "Epoch 53/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9809 - accuracy: 0.7211\n",
      "Epoch 00053: val_accuracy improved from 0.58310 to 0.59230, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.9809 - accuracy: 0.7211 - val_loss: 1.5264 - val_accuracy: 0.5923\n",
      "Epoch 54/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9625 - accuracy: 0.7254\n",
      "Epoch 00054: val_accuracy did not improve from 0.59230\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.9625 - accuracy: 0.7254 - val_loss: 1.5554 - val_accuracy: 0.5863\n",
      "Epoch 55/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9577 - accuracy: 0.7299\n",
      "Epoch 00055: val_accuracy did not improve from 0.59230\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.9577 - accuracy: 0.7299 - val_loss: 1.5611 - val_accuracy: 0.5877\n",
      "Epoch 56/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9318 - accuracy: 0.7345\n",
      "Epoch 00056: val_accuracy did not improve from 0.59230\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.9318 - accuracy: 0.7345 - val_loss: 1.6094 - val_accuracy: 0.5803\n",
      "Epoch 57/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.7394\n",
      "Epoch 00057: val_accuracy did not improve from 0.59230\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.9126 - accuracy: 0.7394 - val_loss: 1.6181 - val_accuracy: 0.5691\n",
      "Epoch 58/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8982 - accuracy: 0.7440\n",
      "Epoch 00058: val_accuracy improved from 0.59230 to 0.59280, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.8982 - accuracy: 0.7440 - val_loss: 1.5366 - val_accuracy: 0.5928\n",
      "Epoch 59/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8854 - accuracy: 0.7474\n",
      "Epoch 00059: val_accuracy did not improve from 0.59280\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.8854 - accuracy: 0.7474 - val_loss: 1.6237 - val_accuracy: 0.5788\n",
      "Epoch 60/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8708 - accuracy: 0.7499\n",
      "Epoch 00060: val_accuracy improved from 0.59280 to 0.59470, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.8708 - accuracy: 0.7499 - val_loss: 1.5071 - val_accuracy: 0.5947\n",
      "Epoch 61/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8435 - accuracy: 0.7585\n",
      "Epoch 00061: val_accuracy did not improve from 0.59470\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.8435 - accuracy: 0.7585 - val_loss: 1.5491 - val_accuracy: 0.5894\n",
      "Epoch 62/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.7598\n",
      "Epoch 00062: val_accuracy did not improve from 0.59470\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.8343 - accuracy: 0.7598 - val_loss: 1.5388 - val_accuracy: 0.5929\n",
      "Epoch 63/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8272 - accuracy: 0.7628\n",
      "Epoch 00063: val_accuracy did not improve from 0.59470\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.8272 - accuracy: 0.7628 - val_loss: 1.6089 - val_accuracy: 0.5820\n",
      "Epoch 64/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8070 - accuracy: 0.7694\n",
      "Epoch 00064: val_accuracy did not improve from 0.59470\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.8070 - accuracy: 0.7694 - val_loss: 1.6260 - val_accuracy: 0.5787\n",
      "Epoch 65/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7926 - accuracy: 0.7736\n",
      "Epoch 00065: val_accuracy improved from 0.59470 to 0.59680, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.7926 - accuracy: 0.7736 - val_loss: 1.5436 - val_accuracy: 0.5968\n",
      "Epoch 66/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7782 - accuracy: 0.7766\n",
      "Epoch 00066: val_accuracy did not improve from 0.59680\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.7782 - accuracy: 0.7766 - val_loss: 1.6997 - val_accuracy: 0.5729\n",
      "Epoch 67/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7642 - accuracy: 0.7798\n",
      "Epoch 00067: val_accuracy improved from 0.59680 to 0.59920, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.7642 - accuracy: 0.7798 - val_loss: 1.5441 - val_accuracy: 0.5992\n",
      "Epoch 68/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7500 - accuracy: 0.7836\n",
      "Epoch 00068: val_accuracy did not improve from 0.59920\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.7500 - accuracy: 0.7836 - val_loss: 1.5789 - val_accuracy: 0.5896\n",
      "Epoch 69/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7375 - accuracy: 0.7875\n",
      "Epoch 00069: val_accuracy did not improve from 0.59920\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.7375 - accuracy: 0.7875 - val_loss: 1.5733 - val_accuracy: 0.5917\n",
      "Epoch 70/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7267 - accuracy: 0.7903\n",
      "Epoch 00070: val_accuracy improved from 0.59920 to 0.60730, saving model to VGG_BatchNOrm_SGD_weights.hdf5\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.7267 - accuracy: 0.7903 - val_loss: 1.5140 - val_accuracy: 0.6073\n",
      "Epoch 71/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7045 - accuracy: 0.7974\n",
      "Epoch 00071: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.7045 - accuracy: 0.7974 - val_loss: 1.5362 - val_accuracy: 0.6038\n",
      "Epoch 72/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.7995\n",
      "Epoch 00072: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.6938 - accuracy: 0.7995 - val_loss: 1.5239 - val_accuracy: 0.6060\n",
      "Epoch 73/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6902 - accuracy: 0.7996\n",
      "Epoch 00073: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.6902 - accuracy: 0.7996 - val_loss: 1.5298 - val_accuracy: 0.6058\n",
      "Epoch 74/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.8022\n",
      "Epoch 00074: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.6777 - accuracy: 0.8022 - val_loss: 1.5519 - val_accuracy: 0.5994\n",
      "Epoch 75/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6609 - accuracy: 0.8095\n",
      "Epoch 00075: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.6609 - accuracy: 0.8095 - val_loss: 1.6188 - val_accuracy: 0.5863\n",
      "Epoch 76/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6450 - accuracy: 0.8145\n",
      "Epoch 00076: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.6450 - accuracy: 0.8145 - val_loss: 1.5635 - val_accuracy: 0.6008\n",
      "Epoch 77/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.8160\n",
      "Epoch 00077: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.6354 - accuracy: 0.8160 - val_loss: 1.5957 - val_accuracy: 0.5989\n",
      "Epoch 78/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.8174\n",
      "Epoch 00078: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.6294 - accuracy: 0.8174 - val_loss: 1.5971 - val_accuracy: 0.5968\n",
      "Epoch 79/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6161 - accuracy: 0.8225\n",
      "Epoch 00079: val_accuracy did not improve from 0.60730\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.6161 - accuracy: 0.8225 - val_loss: 1.7125 - val_accuracy: 0.5730\n",
      "Epoch 80/100\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.8250\n",
      "Epoch 00080: val_accuracy did not improve from 0.60730\n",
      "Restoring model weights from the end of the best epoch.\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.6066 - accuracy: 0.8250 - val_loss: 1.6138 - val_accuracy: 0.5925\n",
      "Epoch 00080: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"VGG_BatchNOrm_SGD_weights.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto',restore_best_weights=True)\n",
    "hist=model.fit(aug_data.flow(x_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch = len(x_train) / 128, epochs=100, validation_data=(x_test, y_test),callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "v2KG3rgvCDHR",
    "outputId": "46fc5e18-622c-4f8e-f27d-b0b9491badfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6239109206279327\n",
      "Recall: 0.6073\n",
      "Accuracy: 0.6073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "HCiek4oKbmiE",
    "outputId": "3da0f136-d147-4e6e-f80b-6d532b39d6bf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ-g65E9njLb"
   },
   "source": [
    "## Cell to Load Weights and Print Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.6239109206279327\n",
      "Recall: 0.6073\n",
      "Accuracy: 0.6073\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense,BatchNormalization,Activation,Dropout,LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "#import tensorflow as \n",
    "model = Sequential()\n",
    "\n",
    "# Creating first block- (2 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same', input_shape= (32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 64, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating second block- (2 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 128, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# Creating third block- (3 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 256, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating fourth block- (3 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating fifth block- (3 Convolution + 1 Max pool)\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Conv2D(filters= 512, kernel_size= (3,3), strides= (1,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(MaxPool2D(pool_size= (2,2), strides=(1,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Flattening the pooled image pixels\n",
    "model.add(Flatten())\n",
    "\n",
    "# Creating 2 Dense Layers\n",
    "model.add(Dense(units= 512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units= 512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# Creating an output layer\n",
    "model.add(Dense(units= 100, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.001,momentum=0.9,clipnorm=1,name='sgd')\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#print(model.summary())\n",
    "\n",
    "from keras.datasets import cifar100\n",
    "(x_train, Y_train), (x_test, Y_test) = cifar100.load_data()\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)\n",
    "\n",
    "model.load_weights('../weights/VGG_BatchNOrm_SGD_weights.hdf5')\n",
    "\n",
    "\n",
    "\n",
    "# Test the model\n",
    "y_true = y_test.argmax(-1)\n",
    "y_pred = model.predict(x_test).argmax(-1)\n",
    "# generate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_true, y_pred)\n",
    "# calculate prec, recall, accuracy\n",
    "print(\"Prec: \"+ str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Recall: \"+ str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VGG_BatchNorm_SGD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
